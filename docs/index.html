<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Generative Models Overview</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://changezakram.github.io/"> <i class="bi bi-house" role="img">
</i> 
<span class="menu-text">Changez Akram</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-generative-ai" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Generative AI</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-generative-ai">    
        <li>
    <a class="dropdown-item" href="./index.html">
 <span class="dropdown-text">Gen AI Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./vae.html">
 <span class="dropdown-text">Variational Autoencoders (VAEs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./flows.html">
 <span class="dropdown-text">Normalizing Flows</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ebm.html">
 <span class="dropdown-text">Energy-Based Models (EBMs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./diffusion.html">
 <span class="dropdown-text">Diffusion Models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-large-language-models" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Large Language Models</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-large-language-models">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/transformers.html">
 <span class="dropdown-text">Transformers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/post-training.html">
 <span class="dropdown-text">Post Training</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/nlp-eval.html">
 <span class="dropdown-text">NLP Evaluation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-agentic-ai" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Agentic AI</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-agentic-ai">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/agentic-ai/agentic-ai.html">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/agentic-ai/agentic-analytics.html">
 <span class="dropdown-text">Agentic Analytics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/slm.html">
 <span class="dropdown-text">Small Language Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/agentic-ai/Workflow-Orchestration.html">
 <span class="dropdown-text">Multi-Agent Orchestration</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/agentic-ai/agentic_ai_security.html">
 <span class="dropdown-text">Securing Agentic AI Systems</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-ai-strategy" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">AI Strategy</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-ai-strategy">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/gen-ai-use-cases/ai_first_bank.html">
 <span class="dropdown-text">Building the AI-First Bank</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/gen-ai-use-cases/banking-use-cases.html">
 <span class="dropdown-text">Gen AI in Banking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/gen-ai-use-cases/healthcare-use-cases.html">
 <span class="dropdown-text">Gen AI in Healthcare</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-math-review" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Math Review</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-math-review">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/linear-algebra.html">
 <span class="dropdown-text">Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/calculus.html">
 <span class="dropdown-text">Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/probability.html">
 <span class="dropdown-text">Probability</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#evolution-of-ai-capabilities" id="toc-evolution-of-ai-capabilities" class="nav-link active" data-scroll-target="#evolution-of-ai-capabilities"><span class="header-section-number">1</span> Evolution of AI Capabilities</a></li>
  <li><a href="#why-generative-ai-matters" id="toc-why-generative-ai-matters" class="nav-link" data-scroll-target="#why-generative-ai-matters"><span class="header-section-number">2</span> Why Generative AI Matters</a></li>
  <li><a href="#how-generative-models-work" id="toc-how-generative-models-work" class="nav-link" data-scroll-target="#how-generative-models-work"><span class="header-section-number">3</span> How Generative Models Work</a></li>
  <li><a href="#how-we-got-here" id="toc-how-we-got-here" class="nav-link" data-scroll-target="#how-we-got-here"><span class="header-section-number">4</span> How We Got Here</a></li>
  <li><a href="#key-gen-ai-model-families" id="toc-key-gen-ai-model-families" class="nav-link" data-scroll-target="#key-gen-ai-model-families"><span class="header-section-number">5</span> Key Gen AI Model Families</a></li>
  <li><a href="#use-case-framing-prioritization" id="toc-use-case-framing-prioritization" class="nav-link" data-scroll-target="#use-case-framing-prioritization"><span class="header-section-number">6</span> Use-Case Framing &amp; Prioritization</a></li>
  <li><a href="#industry-use-cases" id="toc-industry-use-cases" class="nav-link" data-scroll-target="#industry-use-cases"><span class="header-section-number">7</span> Industry Use Cases</a></li>
  <li><a href="#governance-risk-warnings" id="toc-governance-risk-warnings" class="nav-link" data-scroll-target="#governance-risk-warnings"><span class="header-section-number">8</span> Governance &amp; Risk Warnings</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">9</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Generative Models Overview</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="evolution-of-ai-capabilities" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="evolution-of-ai-capabilities"><span class="header-section-number">1</span> Evolution of AI Capabilities</h2>
<p>Generative AI could add $4.4 trillion in annual economic value globally, according to McKinsey. That’s not a distant projection—organizations are already deploying these systems in production. Capturing that value while managing the risks requires understanding where generative AI fits in the broader evolution of AI capabilities.</p>
<p>AI has moved through three distinct phases, each expanding what machines can do while introducing new challenges. <strong>Traditional AI</strong> operates on fixed rules—reliable for repetitive tasks like fraud detection or email filtering, but requiring constant human direction. <strong>Generative AI</strong> learns patterns from data to create new content: text, images, code, synthetic data for testing. <strong>Agentic AI</strong> takes this further, planning multi-step workflows and pursuing goals with minimal human oversight.</p>
<p>Here’s how they compare:</p>
<div style="overflow-x:auto;">
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 28%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Capability</th>
<th><strong>Traditional AI</strong><br><small>Rule-driven tools</small></th>
<th><strong>Generative AI</strong><br><small>Smart assistants</small></th>
<th><strong>Agentic AI</strong><br><small>Autonomous actors</small></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>What it does</strong></td>
<td>Follows hard-coded logic and rules</td>
<td>Understands prompts and generates output</td>
<td>Plans, reasons, and acts across steps</td>
</tr>
<tr class="even">
<td><strong>How it behaves</strong></td>
<td>Rigid, predictable</td>
<td>Creative but guided</td>
<td>Goal-seeking and adaptive</td>
</tr>
<tr class="odd">
<td><strong>Human involvement</strong></td>
<td>Fully manual setup and supervision</td>
<td>Needs context and oversight</td>
<td>Can operate independently (with guardrails)</td>
</tr>
<tr class="even">
<td><strong>Strengths</strong></td>
<td>Reliable on structured tasks</td>
<td>Great at summarizing, drafting, generating</td>
<td>Handles multistep workflows</td>
</tr>
<tr class="odd">
<td><strong>Best used for</strong></td>
<td>Repetitive decisions and automation</td>
<td>Insight generation and copiloting</td>
<td>Full process orchestration</td>
</tr>
</tbody>
</table>
</div>
<p>Each phase unlocked new capabilities but also introduced new failure modes. Traditional AI breaks when edge cases appear. Generative AI can produce convincing but completely incorrect outputs. Agentic AI raises questions about control and accountability when systems operate autonomously. Understanding this progression matters because implementation decisions depend on which type of AI you’re deploying—and in regulated industries like banking and healthcare, the governance requirements differ substantially.</p>
<hr>
</section>
<section id="why-generative-ai-matters" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="why-generative-ai-matters"><span class="header-section-number">2</span> Why Generative AI Matters</h2>
<p>Generative AI creates novel content—text, images, code, synthetic data—by learning patterns from existing examples. Since 2022, adoption has accelerated rapidly. Models like ChatGPT, Claude, and Gemini are deployed across use cases ranging from content generation and fraud detection to software development and clinical documentation.</p>
<blockquote class="blockquote">
<p>McKinsey estimates that generative AI could contribute up to <strong>$4.4 trillion in annual global economic value</strong>, with wide-ranging implications for productivity, personalization, and decision support. However, moving from promise to reality remains challenging. While 88% of organizations now use AI regularly, most are still in the pilot phase. Only about one-third have successfully scaled AI across their enterprises, and just 39% report any measurable impact on earnings. The gap between individual use case success and enterprise-wide transformation is the defining challenge of 2025.</p>
</blockquote>
<p>The technology introduces significant risks alongside its capabilities. GenAI can generate outputs that appear authoritative but are incorrect, biased, or harmful. In banking, healthcare, and legal contexts where errors carry serious consequences, deployment requires strong governance frameworks, human oversight, and careful risk management.</p>
<hr>
</section>
<section id="how-generative-models-work" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="how-generative-models-work"><span class="header-section-number">3</span> How Generative Models Work</h2>
<p>Now that we’ve seen why GenAI matters, let’s look under the hood. How do these models actually learn to create realistic content? The basic idea is pretty simple. These models look at tons of real examples—dog photos, text, whatever—and figure out the patterns. Then they use those patterns to make new stuff that looks real.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/gen-ai.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure 1:</strong> Generative models learn to approximate the true data distribution <span class="math inline">\(P_{\text{data}}\)</span> by optimizing a parameterized model <span class="math inline">\(P_\theta\)</span>. The goal is to minimize divergence <span class="math inline">\(d(P_{\text{data}}, P_\theta)\)</span>. <em>Source: Adapted from Stanford CS236.</em></figcaption>
</figure>
</div>
<p>Here’s what’s going on under the hood:</p>
<p>Real data has patterns. Dog photos usually have four legs, fur, a tail. We call this the data distribution <span class="math inline">\(P_{\text{data}}\)</span>. The model tries to learn this pattern by building its own version, called <span class="math inline">\(P_\theta\)</span> (where <span class="math inline">\(\theta\)</span> represents the model’s internal settings).</p>
<p>Training means adjusting those settings until the model’s distribution <span class="math inline">\(P_\theta\)</span> matches the data distribution <span class="math inline">\(P_{\text{data}}\)</span>. The model keeps tweaking itself to minimize the gap between what it generates and what actually exists. Once trained, you can generate new content by sampling from what the model learned.</p>
<p>The basics:</p>
<ul>
<li>The model learns a pattern <span class="math inline">\(P_\theta\)</span> that captures what makes data look real</li>
<li>New content comes from drawing examples from this learned pattern</li>
<li>Training means making <span class="math inline">\(P_\theta\)</span> match the real data pattern as closely as possible</li>
</ul>
<p><strong>Different models, different approaches:</strong></p>
<p>Different types of models use different techniques to learn these patterns:</p>
<ul>
<li>Autoregressive models (like GPT) and Normalizing Flows directly maximize how likely the real data is under their model</li>
<li>VAEs use a workaround called ELBO (Evidence Lower Bound) to approximate this</li>
<li>GANs pit two networks against each other—one creates fakes, the other spots them—until the fakes become incredibly convincing</li>
<li>Diffusion models and EBMs use techniques like score matching to learn the patterns</li>
</ul>
<p>All these models are trying to learn “what real data looks like” so they can create convincing new examples. They just take different paths to get there.</p>
<hr>
</section>
<section id="how-we-got-here" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="how-we-got-here"><span class="header-section-number">4</span> How We Got Here</h2>
<p>To understand today’s AI, it helps to look back at the key breakthroughs that got us here. The timeline below shows how Generative AI evolved over five distinct periods:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-timeline.png" class="img-fluid figure-img"></p>
<figcaption><strong>Figure:</strong> Generative AI: Key Milestones. Tracks key advances from early neural nets and probabilistic models to modern transformers, diffusion models, and real-world deployment.</figcaption>
</figure>
</div>
<p>Each era built on what came before, introducing new techniques and expanding what AI could do. Let’s walk through each one.</p>
<p><strong>1980–1990s: Early Foundations</strong></p>
<p>In the late 1980s, researchers introduced Recurrent Neural Networks (RNNs), which could process sequences of data like sentences or time series. LSTMs came in 1997, making it easier for models to remember context over longer sequences. Around the same time, early generative models started appearing—a shift from AI that just classified things to AI that could actually create new content. Probabilistic models like Bayesian networks and Hidden Markov Models gave us ways to model uncertainty and complex patterns. These models laid the groundwork for everything that followed.</p>
<p><strong>2000s: Learning Better Representations</strong></p>
<p>The 2000s saw neural networks make a comeback. Researchers figured out how to train them to learn meaningful features from raw data automatically—no hand-crafted rules needed. The big breakthrough was Deep Belief Networks in 2006. They used a clever training trick called layer-wise pretraining that made deep learning practical again after years of disappointing results. This proved that neural networks could learn hierarchical patterns on their own, which opened the door to modern deep learning.</p>
<p><strong>2010s: The Big Leap</strong></p>
<p>This decade brought the models that most people think of as “modern AI.” VAEs showed up in 2013 and GANs in 2014-both could generate realistic images and learn useful representations. Then came Transformers in 2017, which changed everything for language models. Their self-attention mechanism made it possible to build the large language models we use today. Diffusion models appeared in 2015 too, though they didn’t work well until around 2020-2022. Together, these architectures created the foundation for the AI boom we’re seeing now.</p>
<p><strong>2020–2022: Going Big</strong></p>
<p>GPT-3 launched in 2020 and DALL-E 2 in 2022, showing what massive models trained on huge datasets could do—write coherent text, generate photorealistic images. Models got better at zero-shot and few-shot learning, meaning they could handle new tasks without needing specific training. We also saw multimodal models that could work with text, images, and audio all at once. Diffusion models matured during this time too, often producing better images than GANs. This was when GenAI went from a research topic to something people could actually use.</p>
<p><strong>2023–2025: Real-World Deployment</strong></p>
<p>Open-source models like LLaMA and Mistral made powerful AI accessible to more people, not just big tech companies with massive budgets. This competition sped up innovation. Tools like LangChain and RAG emerged to help AI systems handle complex, multi-step tasks and base their answers on real-world data. Companies started deploying GenAI in production, which meant they had to get serious about governance, safety, and explainability.</p>
<blockquote class="blockquote">
<p>The latest frontier is <strong>Agentic AI</strong> that can plan and execute multi-step workflows autonomously. Recent McKinsey research shows that by 2025, nearly two-thirds of organizations are at least experimenting with AI agents, with early adoption concentrated in IT service management and knowledge operations. This shift from AI-as-tool to AI-as-agent marks another evolution in how businesses deploy these technologies.</p>
</blockquote>
<p>Now that we’ve seen how GenAI evolved, let’s dive deeper into the main types of models. Each family has its own way of learning patterns and generating new content.</p>
<hr>
</section>
<section id="key-gen-ai-model-families" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="key-gen-ai-model-families"><span class="header-section-number">5</span> Key Gen AI Model Families</h2>
<p>The generative AI landscape includes several distinct model families, each with its own approach to learning and creating content. Understanding these architectures helps you choose the right tool for specific applications.</p>
<section id="variational-autoencoders-vaes" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="variational-autoencoders-vaes"><span class="header-section-number">5.1</span> Variational Autoencoders (VAEs)</h3>
<p>VAEs compress data into compact representations (latent spaces), then reconstruct it. What makes them useful is how they organize this latent space—similar inputs map to nearby points, which allows smooth interpolation between outputs.</p>
<p><strong>How they learn:</strong> VAEs optimize the Evidence Lower Bound (ELBO), which approximates the true data distribution through a balance of reconstruction accuracy and regularization in the latent space.</p>
<p><strong>Applications &amp; Implementations:</strong> In drug discovery, VAEs generate new molecular structures by learning the latent space of known compounds. Researchers explore this space to find candidates that share properties with existing drugs but have novel structures. Notable implementations include β-VAE for disentangled representations and Conditional VAE for controlled generation.<br>
<a href="./vae.html">Learn more about VAE Models →</a></p>
</section>
<section id="autoregressive-models" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="autoregressive-models"><span class="header-section-number">5.2</span> Autoregressive Models</h3>
<p>Autoregressive models generate sequences one element at a time, where each new element depends on all previous ones. GPT models follow this pattern—they predict each token based on the preceding context.</p>
<p><strong>How they learn:</strong> The training objective is straightforward: maximize the probability of the next token given all previous tokens. This captures sequential dependencies and long-range patterns in the data.</p>
<p><strong>Applications &amp; Implementations:</strong> GPT-4 and Claude generate text by predicting each subsequent token based on context, maintaining coherence across thousands of tokens. GitHub Copilot applies this principle to code generation, suggesting completions based on surrounding code and natural language comments. PixelRNN extends the autoregressive approach to image generation by predicting pixels sequentially.</p>
</section>
<section id="normalizing-flows" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="normalizing-flows"><span class="header-section-number">5.3</span> Normalizing Flows</h3>
<p>Normalizing Flows transform simple distributions (typically Gaussian noise) into complex data distributions through invertible mappings. The reversibility is what sets them apart—you can move from noise to data and back with equal ease.</p>
<p><strong>How they learn:</strong> By chaining invertible transformations, flows can compute exact log-likelihoods—a unique property among generative models. This makes them particularly valuable when precise probability estimates are required.</p>
<p><strong>Applications &amp; Implementations:</strong> WaveGlow uses normalizing flows for natural-sounding speech synthesis. The reversibility also enables density estimation for anomaly detection—determining how likely a particular data point is under the learned distribution. RealNVP and Glow demonstrate the architecture’s flexibility across image and audio domains.<br>
<a href="./flows.html">Learn more about Flow Models →</a></p>
</section>
<section id="energy-based-models-ebms" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="energy-based-models-ebms"><span class="header-section-number">5.4</span> Energy-Based Models (EBMs)</h3>
<p>Energy-Based Models assign scalar energy values to inputs—lower energy corresponds to more probable data. Rather than modeling probabilities directly, EBMs learn what distinguishes realistic data from noise.</p>
<p><strong>How they learn:</strong> Training involves learning an energy function through techniques like contrastive divergence or score matching. Generation requires iterative refinement—starting from random initialization and following the energy gradient toward low-energy regions.</p>
<p><strong>Applications &amp; Implementations:</strong> Score-based diffusion models (a type of EBM) power modern image generators like Midjourney. They learn the score (gradient of the energy) and use it to denoise images step by step, starting from pure noise and arriving at photorealistic results. Training approaches include contrastive divergence and denoising score matching.<br>
<a href="./ebm.html">Learn more about EBMs →</a></p>
</section>
<section id="generative-adversarial-networks-gans" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="generative-adversarial-networks-gans"><span class="header-section-number">5.5</span> Generative Adversarial Networks (GANs)</h3>
<p>GANs train two networks simultaneously: a generator that creates synthetic samples and a discriminator that distinguishes real from generated data. The adversarial training process pushes the generator to produce increasingly realistic outputs.</p>
<p><strong>How they learn:</strong> The training objective is a minimax game where the discriminator maximizes classification accuracy while the generator minimizes it. At equilibrium, the generator’s distribution matches the data distribution.</p>
<p><strong>Applications &amp; Implementations:</strong> StyleGAN generates photorealistic synthetic faces with fine-grained control over attributes, widely adopted for data augmentation and creative tools. CycleGAN enables unpaired image-to-image translation, such as converting photographs to paintings without requiring matched training pairs. The original DALL-E also used a GAN-based architecture before later versions shifted to diffusion.</p>
</section>
<section id="diffusion-models" class="level3" data-number="5.6">
<h3 data-number="5.6" class="anchored" data-anchor-id="diffusion-models"><span class="header-section-number">5.6</span> Diffusion Models</h3>
<p>Diffusion models generate data through iterative denoising. Starting from pure noise, they progressively remove noise over multiple steps until reaching a clean sample. The model learns the reverse of a gradual noising process applied during training.</p>
<p><strong>How they learn:</strong> Training involves two Markov chains: a forward diffusion process that adds Gaussian noise over T steps, and a learned reverse process that denoises. The model learns to predict the noise component at each step, enabling gradual reconstruction from random noise.</p>
<p><strong>Applications &amp; Implementations:</strong> Stable Diffusion and DALL-E 3 generate images from text prompts using this approach. Given a description like “sunset over mountains in Van Gogh style,” the model begins with Gaussian noise and iteratively denoises while conditioning on the encoded text. Midjourney and Imagen represent other leading implementations. Diffusion models have largely supplanted GANs for image synthesis due to superior training stability and sample diversity.<br>
<a href="./diffusion.html">Learn more about Diffusion Models →</a></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Explore Related Topics">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Explore Related Topics
</div>
</div>
<div class="callout-body-container callout-body">
<p>Expand your understanding of Generative AI with these supporting deep dives:</p>
<ul>
<li><p><a href="./transformers.html">Transformers →</a><br>
Understand the self-attention architecture behind modern LLMs and Gen AI models.</p></li>
<li><p><a href="./post-training.html">Post-Training Techniques →</a><br>
Learn how fine-tuning, RLHF, and instruction tuning make base models usable in the real world.</p></li>
<li><p><a href="./nlp-eval.html">Evaluation Strategies →</a><br>
Discover how we evaluate GenAI output quality — from traditional metrics to modern LLM-based approaches.</p></li>
</ul>
</div>
</div>
<hr>
</section>
</section>
<section id="use-case-framing-prioritization" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="use-case-framing-prioritization"><span class="header-section-number">6</span> Use-Case Framing &amp; Prioritization</h2>
<p>Before diving into specific industry use cases, it’s critical to assess <em>where</em> and <em>how</em> generative AI can deliver real value. Not every idea is equally feasible, impactful, or low-risk. A structured framing process helps ensure that AI initiatives align with business priorities and responsible innovation.</p>
<p>We recommend evaluating GenAI use cases across three key dimensions:</p>
<ul>
<li><p><strong>Business Value</strong>: Consider how the use case impacts revenue generation, cost reduction, operational efficiency, risk mitigation, or customer experience. This ensures alignment with strategic business outcomes.</p></li>
<li><p><strong>Feasibility</strong>: Evaluate the availability and quality of data, the readiness of models, the complexity of integration, and infrastructure or compute requirements. This grounds ideas in technical and operational reality.</p></li>
<li><p><strong>Governance Sensitivity</strong>: Assess how much oversight is needed to meet regulatory, ethical, or reputational expectations—especially in domains like banking and healthcare. This includes explainability, auditability, and the potential for misuse.</p></li>
</ul>
<blockquote class="blockquote">
<p>McKinsey research on high-performing AI implementations reveals that workflow redesign is the single strongest predictor of success. Organizations achieving significant business impact don’t just add AI to existing processes—they fundamentally rethink how work gets done. They’re also three times more likely to have senior leadership actively championing AI initiatives and to set growth and innovation goals alongside efficiency targets.</p>
</blockquote>
<p>This framing helps prioritize AI use cases that are not only <strong>promising</strong>, but also <strong>implementable</strong> and <strong>sustainable</strong>—especially in highly regulated environments.</p>
<hr>
</section>
<section id="industry-use-cases" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="industry-use-cases"><span class="header-section-number">7</span> Industry Use Cases</h2>
<p>GenAI is being deployed across industries in two ways: <strong>horizontal use cases</strong> that work everywhere, and <strong>industry-specific applications</strong> tailored to particular sectors. Let’s look at both.</p>
<section id="horizontal-use-cases-apply-across-industries" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="horizontal-use-cases-apply-across-industries"><span class="header-section-number">7.1</span> Horizontal Use Cases (Apply Across Industries)</h3>
<p>These use cases work in nearly any industry—they’re about common business functions like content creation, customer service, and compliance.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 42%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Use Case</strong></th>
<th><strong>What It Does</strong></th>
<th><strong>Business Impact</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Content Generation</strong></td>
<td>Creates reports, emails, social media posts</td>
<td>Scale content marketing efforts without proportional headcount increases</td>
</tr>
<tr class="even">
<td><strong>Personalized Marketing</strong></td>
<td>Generates customized emails, landing pages, and social posts</td>
<td>Reach target audiences more effectively and increase conversion rates</td>
</tr>
<tr class="odd">
<td><strong>Customer Service</strong></td>
<td>Powers chatbots that answer questions and resolve problems</td>
<td>Free up human agents to focus on complex issues</td>
</tr>
<tr class="even">
<td><strong>Risk Management</strong></td>
<td>Identifies and predicts fraud, cyberattacks, supply chain disruptions</td>
<td>Mitigate risks and protect assets before problems occur</td>
</tr>
<tr class="odd">
<td><strong>Compliance</strong></td>
<td>Generates compliant documents like contracts, reports, disclosures</td>
<td>Save time and money while reducing noncompliance risk</td>
</tr>
<tr class="even">
<td><strong>Software Development</strong></td>
<td>Generates code, provides snippets, documents and refactors code</td>
<td>Speed up development, reduce errors, generate test cases</td>
</tr>
<tr class="odd">
<td><strong>Data Augmentation</strong></td>
<td>Creates synthetic data when real data is insufficient</td>
<td>Enable model training when privacy or scarcity limits real data availability</td>
</tr>
<tr class="even">
<td><strong>Contract Management</strong></td>
<td>Drafts legal documents and understands regulatory requirements</td>
<td>Reduce human mistakes and make informed decisions faster</td>
</tr>
</tbody>
</table>
<p>Recent McKinsey data shows cost benefits concentrate in software engineering, manufacturing, and IT operations, while revenue gains primarily come from marketing and sales, strategy functions, and product development. Organizations using AI across multiple functions see better results than those with isolated pilots.</p>
</section>
<section id="banking-financial-services" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="banking-financial-services"><span class="header-section-number">7.2</span> Banking &amp; Financial Services</h3>
<p>Financial institutions use GenAI for scenario modeling, risk assessment, and customer operations—all while navigating strict regulatory requirements.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 84%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Use Case</strong></th>
<th><strong>Example Application</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Customer Service</strong></td>
<td>Virtual agents for handling account queries and FAQs. Bank of America’s <em>Erica</em> has handled <strong>2B+ interactions</strong> with <strong>44-second</strong> average resolution time.</td>
</tr>
<tr class="even">
<td><strong>Fraud Detection</strong></td>
<td>Real-time anomaly detection in transaction behavior. Mastercard <em>Decision Intelligence Pro</em> achieves <strong>20% higher fraud detection</strong> with <strong>85% fewer false positives</strong>.</td>
</tr>
<tr class="odd">
<td><strong>Risk Modeling</strong></td>
<td>Scenario analysis for credit risk and market stress testing.</td>
</tr>
<tr class="even">
<td><strong>Operational Efficiency</strong></td>
<td>Auto-summarizing calls and processing back-office documents. JPMorgan’s <em>COiN</em> reviews <strong>12,000 loan agreements annually</strong>, saving <strong>360,000 hours</strong>.</td>
</tr>
<tr class="odd">
<td><strong>Personalized Insights</strong></td>
<td>Automated note-taking and tailored investment recommendations. Morgan Stanley’s <em>Debrief</em> saves <strong>30 minutes per meeting</strong>, freeing <strong>10–15 hours/week per advisor</strong>.</td>
</tr>
<tr class="even">
<td><strong>Document Summarization</strong></td>
<td>Extracting insights from internal research. Morgan Stanley’s <em>AskResearchGPT</em> summarizes insights from <strong>70,000+ proprietary reports</strong>, saving <strong>90% review time</strong>, cutting costs by <strong>80%</strong>, and improving accuracy by <strong>25%</strong>.</td>
</tr>
<tr class="odd">
<td><strong>Business Intelligence</strong></td>
<td>Spotting unusual patterns in product or branch-level KPIs.</td>
</tr>
<tr class="even">
<td><strong>Marketing &amp; Personalization</strong></td>
<td>Creating personalized offers based on customer behavior and transaction history.</td>
</tr>
<tr class="odd">
<td><strong>Product Development</strong></td>
<td>Simulating scenarios to develop new financial products and services.</td>
</tr>
</tbody>
</table>
<p><strong>What makes financial services different:</strong><br>
Decision-making requires scenario simulation, risk model assessment, and customer personalization based on transaction history. Everything must be explainable and auditable for regulators.</p>
<blockquote class="blockquote">
<p>Real-world examples from JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley.<br>
<strong><a href="gen-ai-use-cases/banking-use-cases.html">View complete banking implementation guide →</a></strong></p>
</blockquote>
<hr>
</section>
<section id="healthcare-life-sciences" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="healthcare-life-sciences"><span class="header-section-number">7.3</span> Healthcare &amp; Life Sciences</h3>
<p>Healthcare organizations deploy GenAI for drug discovery, clinical documentation, and personalized treatment—all while maintaining patient privacy and safety standards.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 86%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Use Case</strong></th>
<th><strong>Example Application</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Clinical Documentation</strong></td>
<td>Auto-generating visit summaries and physician notes. Nuance DAX reduces documentation time by <strong>50%</strong>, saving <strong>7 minutes per encounter</strong> and enabling <strong>3–5 additional appointments</strong> daily.</td>
</tr>
<tr class="even">
<td><strong>Drug Discovery</strong></td>
<td>Accelerating compound generation and molecular simulation. <em>Insilico Medicine</em> advanced a drug candidate to Phase II trials in <strong>under 30 months</strong> (<em>&lt;18 months</em> from target to candidate).</td>
</tr>
<tr class="odd">
<td><strong>Medical Device Design</strong></td>
<td>Creating and optimizing new medical devices.</td>
</tr>
<tr class="even">
<td><strong>Treatment Plans</strong></td>
<td>Generating personalized patient treatment plans.</td>
</tr>
<tr class="odd">
<td><strong>Medical Imaging</strong></td>
<td>Improving and reconstructing radiological images. <em>MIT CSAIL’s AI</em> reduced false positives by <strong>37.3%</strong>, biopsy rates by <strong>27.8%</strong>, and unnecessary surgeries by <strong>over 30%</strong>.</td>
</tr>
<tr class="even">
<td><strong>Diagnostics &amp; Triage</strong></td>
<td>Supporting diagnosis with uncertainty-aware modeling (confidence scores).</td>
</tr>
<tr class="odd">
<td><strong>Patient Education</strong></td>
<td>Explaining test results, medication instructions, and drug interactions in plain language.</td>
</tr>
</tbody>
</table>
<p><strong>What makes healthcare different:</strong><br>
GenAI develops new drugs and treatments, designs medical devices, creates personalized treatment plans, and generates patient documentation on instructions, risks, and drug interactions. Patient safety and privacy (HIPAA) are non-negotiable.</p>
<blockquote class="blockquote">
<p>Examples from Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine.<br>
<strong><a href="gen-ai-use-cases/healthcare-use-cases.html">View complete healthcare implementation guide →</a></strong></p>
</blockquote>
<hr>
</section>
</section>
<section id="governance-risk-warnings" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="governance-risk-warnings"><span class="header-section-number">8</span> Governance &amp; Risk Warnings</h2>
<p>Generative AI introduces exciting new capabilities—but also carries <strong>unique risks</strong> that traditional analytics and rules-based systems did not. Without strong governance, these risks can quickly undermine trust, compliance, and effectiveness.</p>
<p><strong>What Happens When Governance Fails</strong></p>
<p>We’re already seeing what goes wrong when organizations skip governance.</p>
<p>Bank of America found out in 2020 during the COVID unemployment surge. They deployed automated fraud detection—basically a simple set of flags that would freeze suspicious accounts. It caught fraud, sure, but it also locked tens of thousands of legitimate customers out of their unemployment benefits. And the bank had long hold times and limited staff to help people unfreeze accounts, which made a bad situation worse. The bill came to $225 million in regulatory fines, plus hundreds of millions more in customer refunds. Regulators said it violated the Electronic Fund Transfer Act. The real problem wasn’t the automation—it was taking humans out of the loop without building in ways to catch and fix mistakes.</p>
<p>In 2024, the SEC went after two investment advisers for what they called “AI-washing”—basically lying about AI capabilities to attract investors. Delphia claimed it used machine learning to “predict which companies and trends are about to make it big” using client data. They’d been saying this since 2019. Global Predictions went even further, calling itself the “first regulated AI financial advisor” with “expert AI-driven forecasts.” When SEC examiners showed up and asked for documentation? There wasn’t any. Delphia had actually admitted back in 2021 they didn’t have the algorithm they’d been marketing, then kept making the same claims for two more years. The penalties hit $400,000 combined, plus censures. SEC Chair Gary Gensler didn’t sugarcoat it: “Investment advisers should not mislead the public by saying they are using an AI model when they are not.”</p>
<p><strong>Key Risks to Watch:</strong></p>
<ul>
<li><strong>Inaccuracy &amp; Hallucination</strong>: GenAI can confidently generate responses that sound right—but are completely wrong or misleading.</li>
<li><strong>Bias &amp; Fairness</strong>: Models can unintentionally reinforce historical bias found in training data. These outcomes could affect customers or patients.</li>
<li><strong>Security &amp; Privacy</strong>: Prompts or training data may inadvertently expose sensitive, private, or proprietary information.</li>
<li><strong>Overtrust</strong>: Users may take outputs at face value without critical thinking, especially in high-volume environments like BI dashboards or chatbots.</li>
<li><strong>Regulatory Exposure</strong>: Lack of transparency, explainability, or auditability may put the organization at odds with standards such as OCC guidelines, HIPAA, GDPR, or emerging AI laws.</li>
</ul>
<blockquote class="blockquote">
<p>These risks are not hypothetical. McKinsey surveys show that 51% of organizations using AI have already experienced at least one negative consequence, with inaccuracy being the most commonly reported issue. High-performing organizations—those deploying more AI use cases—experience more problems but also invest more heavily in mitigation. The average organization now actively addresses four AI-related risks, double the number from just three years ago.</p>
</blockquote>
<p><strong>Governance Practices to Put in Place:</strong></p>
<ul>
<li><strong>Human-in-the-Loop (HITL)</strong>: Require review and validation for GenAI-generated content in regulated or customer-facing contexts.</li>
<li><strong>Explainability &amp; Traceability</strong>: Where possible, use interpretable model frameworks, or add metadata like model version, confidence score, or decision path.</li>
<li><strong>Prompt &amp; Output Logging</strong>: Maintain logs of GenAI usage for auditing, debugging, and continuous refinement.</li>
<li><strong>Access Control &amp; Masking</strong>: Limit who can access GenAI systems and ensure sensitive data is redacted before prompt injection or model training.</li>
<li><strong>Alignment with Ethical and Regulatory Frameworks</strong>: Embed enterprise values and industry-specific compliance into your AI lifecycle—from design to deployment.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Bottom line</strong>: In highly regulated industries like banking and healthcare, governance isn’t just a best practice—it’s a business requirement. The goal is to innovate responsibly and scale safely.</p>
</blockquote>
<hr>
</section>
<section id="conclusion" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">9</span> Conclusion</h2>
<p>Generative AI is changing how we create and use content—not just incrementally, but fundamentally. Many organizations are past the demo phase now. The real work is figuring out which use cases actually deliver value, building governance that works in practice (not just on paper), and getting this integrated into workflows people actually use. The next few years won’t be about who has the flashiest model. It’ll be about execution—who can deploy at scale without compliance blowups, team burnout, or budget overruns on projects that go nowhere. We’ll see more intelligent copilots that understand business context, agents that handle complex workflows, and hopefully AI systems with governance baked in from the start instead of patched on later when regulators come knocking.</p>
<p>In financial services especially, the pattern is pretty clear. Organizations getting this right treat AI as business transformation, not a technology project. They ask the hard questions early: Does this solve a real problem? How do we know it’s working? What’s our plan when it fails? Can we actually explain this to regulators? Skip those questions and you end up like the examples we covered—Bank of America paying $225 million in fines, investment advisers getting hit for making false AI claims. The penalties are real, the reputational damage sticks around, and trying to retrofit governance after the fact is brutal.</p>
<p>The competitive advantage goes to companies that figure out the balance—moving fast while staying compliant, automating intelligently while keeping humans in the right places. Everyone else gets left behind.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>