<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>NLP Model Evaluation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://changezakram.github.io/"> <i class="bi bi-house" role="img">
</i> 
<span class="menu-text">Changez Akram</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-generative-ai" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Generative AI</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-generative-ai">    
        <li>
    <a class="dropdown-item" href="./vae.html">
 <span class="dropdown-text">Variational Autoencoders (VAEs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./flows.html">
 <span class="dropdown-text">Normalizing Flows</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./ebm.html">
 <span class="dropdown-text">Energy-Based Models (EBMs)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./diffusion.html">
 <span class="dropdown-text">Diffusion Models</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-large-language-models" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Large Language Models</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-large-language-models">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/transformers.html">
 <span class="dropdown-text">Transformers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/post-training.html">
 <span class="dropdown-text">Post Training</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/nlp-eval.html">
 <span class="dropdown-text">NLP Evaluation</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-agentic-ai" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Agentic AI</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-agentic-ai">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/agentic-ai/agentic-ai.html">
 <span class="dropdown-text">Introduction</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-math-review" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Math Review</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-math-review">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/linear-algebra.html">
 <span class="dropdown-text">Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/calculus.html">
 <span class="dropdown-text">Calculus</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/math-review/probability.html">
 <span class="dropdown-text">Probability</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-use-cases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Use Cases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-use-cases">    
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/gen-ai-use-cases/banking-use-cases.html">
 <span class="dropdown-text">Banking</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://changezakram.github.io/Deep-Generative-Models/gen-ai-use-cases/healthcare-use-cases.html">
 <span class="dropdown-text">Healthcare</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction:</a></li>
  <li><a href="#despite-these-challenges-closed-ended-evaluation-remains-a-valuable-starting-point.-its-well-constrained-answer-space-allows-use-of-established-metrics-like-accuracy-precision-recall-and-f1-score-to-measure-progress-systematically." id="toc-despite-these-challenges-closed-ended-evaluation-remains-a-valuable-starting-point.-its-well-constrained-answer-space-allows-use-of-established-metrics-like-accuracy-precision-recall-and-f1-score-to-measure-progress-systematically." class="nav-link" data-scroll-target="#despite-these-challenges-closed-ended-evaluation-remains-a-valuable-starting-point.-its-well-constrained-answer-space-allows-use-of-established-metrics-like-accuracy-precision-recall-and-f1-score-to-measure-progress-systematically."><span class="header-section-number">2</span> Despite these challenges, closed-ended evaluation remains a valuable starting point. Its well-constrained answer space allows use of established metrics like accuracy, precision, recall, and F1-score to measure progress systematically.</a></li>
  <li><a href="#references-further-reading" id="toc-references-further-reading" class="nav-link" data-scroll-target="#references-further-reading"><span class="header-section-number">3</span> References &amp; Further Reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">NLP Model Evaluation</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1</span> Introduction:</h2>
<p>Evaluating NLP models presents distinct challenges for both <strong>closed-ended</strong> and <strong>open-ended</strong> tasks, and these have become more complex with the rise of foundation models.</p>
<ul>
<li><strong>Closed-ended tasks</strong> (e.g., classification, named entity recognition) have clearly defined outputs and ground-truth labels. While traditional ML evaluation methods like accuracy, precision, recall, and F1-score are applicable here, they still face issues such as task ambiguity, annotation bias, and benchmark saturation.</li>
<li><strong>Open-ended tasks</strong> (e.g., summarization, question answering, code generation, dialogue) are more difficult to evaluate because there is often no single correct output. The outputs are probabilistic and highly variable, which makes defining and applying evaluation metrics far more complex.</li>
</ul>
<p>According to the <em>AI Engineering</em> book, evaluating the output of more intelligent models—especially open-ended ones—is especially difficult. A first-grader’s math mistake is easy to spot, but determining whether an AI-generated summary is factually accurate often requires reading and understanding the full source text.</p>
<p>Traditional ML evaluation assumes relatively stable output spaces and ground truth labels. However, foundation models produce diverse and nuanced outputs that challenge this assumption. As a result, even closed-ended tasks must now contend with emerging evaluation issues such as:</p>
<ul>
<li><strong>Evaluation scalability</strong>: Automated metrics work well, but can overlook nuance.</li>
<li><strong>Annotation bias</strong>: Even in classification tasks, human-created datasets often have spurious correlations.</li>
<li><strong>Benchmark saturation</strong>: As models improve, they quickly saturate existing benchmarks, giving a false sense of progress.</li>
<li><strong>Undersupported evaluation infrastructure</strong>: The <em>AI Engineering</em> book notes that evaluation lags behind other areas like model training, optimization, and deployment tooling.</li>
</ul>
</section>
<section id="despite-these-challenges-closed-ended-evaluation-remains-a-valuable-starting-point.-its-well-constrained-answer-space-allows-use-of-established-metrics-like-accuracy-precision-recall-and-f1-score-to-measure-progress-systematically." class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="despite-these-challenges-closed-ended-evaluation-remains-a-valuable-starting-point.-its-well-constrained-answer-space-allows-use-of-established-metrics-like-accuracy-precision-recall-and-f1-score-to-measure-progress-systematically."><span class="header-section-number">2</span> Despite these challenges, closed-ended evaluation remains a valuable starting point. Its well-constrained answer space allows use of established metrics like accuracy, precision, recall, and F1-score to measure progress systematically.</h2>
<section id="key-characteristics-of-closed-ended-tasks" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="key-characteristics-of-closed-ended-tasks"><span class="header-section-number">2.1</span> Key Characteristics of Closed-Ended Tasks</h3>
<ul>
<li>Limited number of potential answers</li>
<li>Often only one or a few correct answers</li>
<li>Enables automatic and scalable evaluation, making them well-suited for benchmarking</li>
</ul>
<hr>
</section>
<section id="common-closed-ended-tasks-benchmarks" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="common-closed-ended-tasks-benchmarks"><span class="header-section-number">2.2</span> Common Closed-Ended Tasks &amp; Benchmarks</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 48%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Task Type</th>
<th>Description</th>
<th>Popular Benchmarks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sentiment Analysis</strong></td>
<td>Classify sentiment as Positive, Negative, Neutral</td>
<td>SST, IMDB, Yelp</td>
</tr>
<tr class="even">
<td><strong>Textual Entailment</strong></td>
<td>Determine if a hypothesis logically follows from a premise</td>
<td>SNLI, RTE</td>
</tr>
<tr class="odd">
<td><strong>Named Entity Recognition</strong></td>
<td>Identify named entities in text</td>
<td>CoNLL-2003</td>
</tr>
<tr class="even">
<td><strong>Part-of-Speech Tagging</strong></td>
<td>Assign parts of speech to each word</td>
<td>PTB</td>
</tr>
<tr class="odd">
<td><strong>Coreference Resolution</strong></td>
<td>Determine if pronouns refer to the same entity</td>
<td>WSC</td>
</tr>
<tr class="even">
<td><strong>Question Answering</strong></td>
<td>Extract a plausible answer from a given passage</td>
<td>SQuAD2</td>
</tr>
</tbody>
</table>
<section id="example-sentiment-analysis" class="level4" data-number="2.2.1">
<h4 data-number="2.2.1" class="anchored" data-anchor-id="example-sentiment-analysis"><span class="header-section-number">2.2.1</span> Example: Sentiment Analysis</h4>
<ul>
<li><strong>Text</strong>: “Read the book, forget the movie!”<br>
</li>
<li><strong>Label</strong>: Negative</li>
</ul>
</section>
<section id="example-entailment" class="level4" data-number="2.2.2">
<h4 data-number="2.2.2" class="anchored" data-anchor-id="example-entailment"><span class="header-section-number">2.2.2</span> Example: Entailment</h4>
<ul>
<li><strong>Premise</strong>: “A soccer game with multiple males playing.”<br>
</li>
<li><strong>Hypothesis</strong>: “Some men are playing sport.”<br>
</li>
<li><strong>Label</strong>: Entailment</li>
</ul>
<hr>
</section>
</section>
<section id="multi-task-benchmark-superglue" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="multi-task-benchmark-superglue"><span class="header-section-number">2.3</span> Multi-Task Benchmark: <strong>SuperGLUE</strong></h3>
<p>SuperGLUE is a widely used <strong>closed-ended multi-task benchmark</strong> designed to test <strong>general language understanding</strong>. It evaluates performance across diverse NLP tasks.</p>
<section id="tasks-in-superglue" class="level4" data-number="2.3.1">
<h4 data-number="2.3.1" class="anchored" data-anchor-id="tasks-in-superglue"><span class="header-section-number">2.3.1</span> Tasks in SuperGLUE:</h4>
<ul>
<li><strong>BoolQ, MultiRC</strong>: Reading comprehension<br>
</li>
<li><strong>CB, RTE</strong>: Natural language inference (entailment)<br>
</li>
<li><strong>COPA</strong>: Causal reasoning (cause and effect)<br>
</li>
<li><strong>ReCoRD</strong>: Reading comprehension with commonsense reasoning<br>
</li>
<li><strong>WiC</strong>: Word meaning in context<br>
</li>
<li><strong>WSC</strong>: Coreference resolution</li>
</ul>
</section>
<section id="leaderboard-highlights-v2.0" class="level4" data-number="2.3.2">
<h4 data-number="2.3.2" class="anchored" data-anchor-id="leaderboard-highlights-v2.0"><span class="header-section-number">2.3.2</span> Leaderboard Highlights (v2.0):</h4>
<ul>
<li><strong>Top models</strong>: Vega v2, ST-MoE-32B, ERNIE, PaLM 540B, T5<br>
</li>
<li><strong>Metrics used</strong>: Accuracy, F1 score, Exact Match, Gender Parity, etc.</li>
</ul>
<hr>
</section>
</section>
<section id="challenges-in-closed-ended-evaluation" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="challenges-in-closed-ended-evaluation"><span class="header-section-number">2.4</span> Challenges in Closed-Ended Evaluation</h3>
<ol type="1">
<li><p><strong>Choosing the Right Metric</strong></p>
<p>Choosing the right evaluation metric is not trivial. Different tasks and datasets require different performance measures. For instance, accuracy may seem intuitive but can be misleading on imbalanced datasets. A model might achieve high accuracy simply by predicting the majority class. On the other hand, recall and precision offer complementary perspectives: one focusing on completeness (recall) and the other on correctness (precision). The choice of metric directly impacts how model performance is interpreted, compared, and optimized. In multi-class or skewed-distribution scenarios, using a single metric without understanding its limitations can mask critical weaknesses.</p>
<div class="sidebar">
<h4 id="common-evaluation-metrics" data-number="2.4.1" class="anchored"><span class="header-section-number">2.4.1</span> Common Evaluation Metrics</h4>
<ul>
<li><strong>Accuracy</strong>: The proportion of correct predictions out of all predictions. Suitable for balanced datasets.</li>
<li><strong>Precision</strong>: The proportion of true positives out of all predicted positives. High precision means fewer false positives.</li>
<li><strong>Recall</strong>: The proportion of true positives out of all actual positives. High recall means fewer false negatives.</li>
<li><strong>F1-Score</strong>: The harmonic mean of precision and recall. Useful when there is an uneven class distribution.</li>
<li><strong>ROC AUC (Receiver Operating Characteristic - Area Under Curve)</strong>: Measures the ability of the model to distinguish between classes across thresholds. Higher AUC indicates better performance.</li>
</ul>
</div></li>
<li><p><strong>Aggregating Metrics</strong></p>
<ul>
<li>How to combine across multiple tasks or sub-tasks</li>
</ul></li>
<li><p><strong>Label Quality</strong></p>
<ul>
<li>Are the gold-standard labels always reliable?<br>
</li>
<li>Are there ambiguities in annotation?</li>
</ul></li>
<li><p><strong>Spurious Correlations</strong></p>
<ul>
<li>Models might exploit dataset artifacts rather than genuinely learning the task<br>
</li>
<li><strong>Example</strong> (SNLI):
<ul>
<li>Premise: “The economy could be still better.”<br>
</li>
<li>Hypothesis: “The economy has <em>never</em> been better.”<br>
</li>
<li>Model might infer contradiction simply due to the word <em>never</em> rather than actual reasoning</li>
</ul></li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="references-further-reading" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="references-further-reading"><span class="header-section-number">3</span> References &amp; Further Reading</h2>
<p>[16] Huyen, C. (2024). <em>AI Engineering: Building Applications with Foundation Models</em>. O’Reilly Media.</p>
<p>[17] Alammar, J., &amp; Grootendorst, M. (2023). <em>Hands-On Large Language Models: Language Understanding and Generation</em>. O’Reilly Media.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>