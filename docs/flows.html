<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Normalizing Flow Models â€“ Deep Generative Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a14e3238c51140e99ccc48519b6ed9ce.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="styles.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Deep Generative Models</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Normalizing Flow Models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In generative modeling, the objective is to learn a probability distribution over data that allows us to both <strong>generate new examples</strong> and <strong>evaluate the likelihood</strong> of observed ones. For a model to be practically useful, it must support <strong>efficient sampling</strong> and enable <strong>exact or tractable likelihood computation</strong> during training.</p>
<p><strong>A Variational Autoencoder (VAE)</strong> is a type of generative model that introduces latent variables <span class="math inline">\(z\)</span>, allowing the model to learn compact, structured representations of the data. VAEs are designed to support both sampling and likelihood estimation. However, computing the true marginal likelihood <span class="math inline">\(p(x)\)</span> is often intractable. To address this, VAEs use <strong>variational inference</strong> to approximate the posterior <span class="math inline">\(p(z \mid x)\)</span> and optimize a surrogate objective known as the <strong>Evidence Lower Bound (ELBO)</strong>. This is made possible by the <strong>reparameterization trick</strong>, which enables gradients to flow through stochastic latent variables during training.</p>
<p><strong>Normalizing flows</strong> address the limitations of VAEs by providing a way to perform exact inference and likelihood computation. They model complex data distributions using a sequence of invertible transformations applied to a simple base distribution. In this setup, a data point <span class="math inline">\(x\)</span> is generated by applying a function <span class="math inline">\(x = f(z)\)</span> to a latent variable <span class="math inline">\(z\)</span> sampled from a simple prior (e.g., a standard Gaussian). The transformation is invertible, so <span class="math inline">\(z\)</span> can be exactly recovered as <span class="math inline">\(z = f^{-1}(x)\)</span>. This structure enables direct access to both the data likelihood and latent variables using the change-of-variables formula.</p>
<p>This structure offers several advantages. First, <strong>each <span class="math inline">\(x\)</span> maps to a unique <span class="math inline">\(z\)</span></strong>, eliminating the need to marginalize over latent variables as in VAEs. Second, the <strong>change-of-variables formula</strong> enables <strong>exact computation of the likelihood</strong>, rather than approximations. Third, <strong>sampling is straightforward</strong>: draw <span class="math inline">\(z \sim p_Z(z)\)</span> from the base distribution and apply the transformation <span class="math inline">\(x = f(z)\)</span>.</p>
<p>Despite these strengths, normalizing flows have limitations. Unlike VAEs, which can learn <strong>lower-dimensional latent representations</strong>, flows require the latent and data spaces to have <strong>equal dimensionality</strong> to preserve invertibility. This means flow-based models <strong>do not perform dimensionality reduction</strong>, which can be a disadvantage in tasks where compact representations are important.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/vae_vs_flow.png" class="img-fluid figure-img"></p>
<figcaption>Comparison of VAE and Flow-based Models</figcaption>
</figure>
</div>
<p><em>VAEs compress data into a lower-dimensional latent space using an encoder, then reconstruct it with a decoder. Flow-based models use a single invertible transformation that keeps the same dimensionality between input and latent space. This enables exact inference and likelihood computation.</em></p>
<p>To understand how normalizing flows enable exact likelihood computation, we first need to explore a fundamental mathematical concept: the change-of-variable formula. This principle lies at the heart of flow models, allowing us to transform probability densities through invertible functions. Weâ€™ll begin with the 1D case and build up to the multivariate formulation.</p>
</section>
<section id="math-review-change-of-variables-in-1d" class="level2">
<h2 class="anchored" data-anchor-id="math-review-change-of-variables-in-1d">Math Review: Change of Variables in 1D</h2>
<p>Suppose we have a <strong>random variable</strong> <span class="math inline">\(z\)</span> with a known distribution <span class="math inline">\(p_Z(z)\)</span>, and we define a new variable:</p>
<p><span class="math display">\[
x = f(z)
\]</span></p>
<p>where <span class="math inline">\(f\)</span> is a <strong>monotonic, differentiable</strong> function with an inverse:</p>
<p><span class="math display">\[
z = f^{-1}(x) = h(x)
\]</span></p>
<p>Our goal is to compute the probability density function (PDF) of <span class="math inline">\(x\)</span>, denoted <span class="math inline">\(p_X(x)\)</span>, in terms of the known PDF <span class="math inline">\(p_Z(z)\)</span>.</p>
<section id="step-1-cumulative-distribution-function-cdf" class="level3">
<h3 class="anchored" data-anchor-id="step-1-cumulative-distribution-function-cdf">Step 1: Cumulative Distribution Function (CDF)</h3>
<p>We begin with the cumulative distribution function of <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
F_X(x) = P(X \leq x) = P(f(Z) \leq x)
\]</span></p>
<p>Since <span class="math inline">\(f\)</span> is monotonic and invertible, this becomes:</p>
<p><span class="math display">\[
P(f(Z) \leq x) = P(Z \leq f^{-1}(x)) = F_Z(h(x))
\]</span></p>
</section>
<section id="step-2-deriving-the-pdf-via-chain-rule" class="level3">
<h3 class="anchored" data-anchor-id="step-2-deriving-the-pdf-via-chain-rule">Step 2: Deriving the PDF via Chain Rule</h3>
<p>To obtain the PDF, we differentiate the CDF:</p>
<p><span class="math display">\[
p_X(x) = \frac{d}{dx} F_X(x) = \frac{d}{dx} F_Z(h(x))
\]</span></p>
<p>Applying the chain rule:</p>
<p><span class="math display">\[
p_X(x) = F_Z'(h(x)) \cdot h'(x) = p_Z(h(x)) \cdot h'(x)
\]</span></p>
</section>
<section id="step-3-rewrite-in-terms-of-z" class="level3">
<h3 class="anchored" data-anchor-id="step-3-rewrite-in-terms-of-z">Step 3: Rewrite in Terms of <span class="math inline">\(z\)</span></h3>
<p>From the previous step:</p>
<p><span class="math display">\[
p_X(x) = p_Z(h(x)) \cdot h'(x)
\]</span></p>
<p>Since <span class="math inline">\(z = h(x)\)</span>, we can rewrite:</p>
<p><span class="math display">\[
p_X(x) = p_Z(z) \cdot h'(x)
\]</span></p>
<p>Now, using the <strong>inverse function theorem</strong>, we express <span class="math inline">\(h'(x)\)</span> as:</p>
<p><span class="math display">\[
h'(x) = \frac{d}{dx} f^{-1}(x) = \frac{1}{f'(z)}
\]</span></p>
<p>So the final expression becomes:</p>
<p><span class="math display">\[
p_X(x) = p_Z(z) \cdot \left| \frac{1}{f'(z)} \right|
\]</span></p>
<p>The <strong>absolute value</strong> ensures the density remains non-negative, as required for any valid probability distribution.</p>
<p>This is the fundamental concept normalizing flows use to model complex distributions by transforming simple ones.</p>
</section>
</section>
<section id="geometry-determinants-and-volume-changes" class="level2">
<h2 class="anchored" data-anchor-id="geometry-determinants-and-volume-changes">Geometry: Determinants and Volume Changes</h2>
<p>To understand the multivariate change-of-variable formula, itâ€™s helpful to first explore how transformations affect <strong>volume</strong> in high-dimensional spaces.</p>
<p>Let <span class="math inline">\(\mathbf{Z}\)</span> be a random vector uniformly distributed in the unit cube <span class="math inline">\([0,1]^n\)</span>, and let <span class="math inline">\(\mathbf{X} = A\mathbf{Z}\)</span> where <span class="math inline">\(A\)</span> is a square, invertible matrix. Geometrically, the matrix <span class="math inline">\(A\)</span> maps the unit hypercube to a <strong>parallelogram</strong> (in 2D) or a <strong>parallelotope</strong> (in higher dimensions).</p>
<p>The <strong>determinant</strong> of a square matrix tells us how that matrix <strong>scales volume</strong> in space. For example, if the determinant of a <span class="math inline">\(2 \times 2\)</span> matrix is 3, then applying that matrix to a region will stretch its area by a factor of 3. A negative determinant also indicates a <strong>reflection</strong> (orientation reversal). The <strong>absolute value</strong> of the determinant is what we care about when measuring volume.</p>
<p>The <strong>volume</strong> of this parallelotope is equal to the <strong>absolute value of the determinant</strong> of matrix <span class="math inline">\(A\)</span>:</p>
<p><span class="math display">\[
\text{Volume} = |\det(A)|
\]</span></p>
<p>This tells us how much the transformation <span class="math inline">\(A\)</span> <strong>scales space</strong>. For example, if <span class="math inline">\(|\det(A)| = 2\)</span>, the transformation doubles the volume. To make this idea more concrete, consider the following illustration:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/determinant_area.png" class="img-fluid figure-img"></p>
<figcaption>Linear transformation of a unit square into a parallelogram</figcaption>
</figure>
</div>
<p><em>Figure: A linear transformation maps a unit square to a parallelogram. The area of this parallelogram is equal to the absolute value of the determinant ( |(A)| = |ad - bc| ).</em></p>
</section>
<section id="determinants-and-probability-density" class="level2">
<h2 class="anchored" data-anchor-id="determinants-and-probability-density">Determinants and Probability Density</h2>
<p>Now suppose we apply the linear transformation <span class="math inline">\(\mathbf{X} = A\mathbf{Z}\)</span> to a random vector <span class="math inline">\(\mathbf{Z}\)</span> with a known density <span class="math inline">\(p_Z\)</span>. The new density after transformation is:</p>
<p><span class="math display">\[
p_X(\mathbf{x}) = p_Z(W\mathbf{x}) \cdot |\det(W)| \quad \text{where} \quad W = A^{-1}
\]</span></p>
<p>This is directly analogous to the 1D change-of-variable rule:</p>
<p><span class="math display">\[
p_X(x) = p_Z(h(x)) \cdot |h'(x)|
\]</span></p>
<p>but now in multiple dimensions using the determinant of the <strong>inverse transformation</strong>.</p>
</section>
<section id="generalizing-to-nonlinear-transformations" class="level2">
<h2 class="anchored" data-anchor-id="generalizing-to-nonlinear-transformations">Generalizing to Nonlinear Transformations</h2>
<p>For <strong>nonlinear</strong> transformations <span class="math inline">\(\mathbf{x} = f(\mathbf{z})\)</span>, the idea is similar. But instead of a constant matrix <span class="math inline">\(A\)</span>, we now consider the <strong>Jacobian matrix</strong> of the function <span class="math inline">\(f\)</span>:</p>
<p><span class="math display">\[
J_f(\mathbf{z}) = \frac{\partial f}{\partial \mathbf{z}}
\]</span></p>
<p>This Jacobian tells us how the function scales and rotates space <strong>locally</strong> around a point <span class="math inline">\(\mathbf{z}\)</span>. The <strong>determinant of the Jacobian</strong> gives the volume change factor at that point.</p>
</section>
<section id="multivariate-change-of-variable-formula" class="level2">
<h2 class="anchored" data-anchor-id="multivariate-change-of-variable-formula">Multivariate Change-of-Variable Formula</h2>
<p>Given an invertible transformation <span class="math inline">\(\mathbf{x} = f(\mathbf{z})\)</span>, the probability density transforms as:</p>
<p><span class="math display">\[
p_X(\mathbf{x}) = p_Z(f^{-1}(\mathbf{x})) \cdot \left| \det \left( \frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}} \right) \right|
\]</span></p>
<p>Alternatively, in the <strong>forward form</strong> (often used during training):</p>
<p><span class="math display">\[
p_X(\mathbf{x}) = p_Z(\mathbf{z}) \cdot \left| \det \left( \frac{\partial f(\mathbf{z})}{\partial \mathbf{z}} \right) \right|^{-1}
\]</span></p>
<p>This generalizes the 1D rule and enables us to compute <strong>exact likelihoods</strong> for complex distributions as long as the transformation is invertible and differentiable.</p>
</section>
<section id="model-formulation" class="level2">
<h2 class="anchored" data-anchor-id="model-formulation">Model Formulation</h2>
<p>A normalizing flow model defines a <strong>one-to-one and reversible transformation</strong> between observed variables <span class="math inline">\(\mathbf{x}\)</span> and latent variables <span class="math inline">\(\mathbf{z}\)</span>. This transformation is given by an invertible, differentiable function <span class="math inline">\(f_\theta\)</span>, parameterized by <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[
\mathbf{x} = f_\theta(\mathbf{z}) \quad \text{and} \quad \mathbf{z} = f_\theta^{-1}(\mathbf{x})
\]</span></p>
<p>Because the transformation is invertible, we can apply the <strong>change-of-variable formula</strong> to compute the exact probability of <span class="math inline">\(\mathbf{x}\)</span>:</p>
<p><span class="math display">\[
p_X(\mathbf{x}; \theta) = p_Z(f_\theta^{-1}(\mathbf{x})) \cdot \left| \det \left( \frac{\partial f_\theta^{-1}(\mathbf{x})}{\partial \mathbf{x}} \right) \right|
\]</span></p>
<p>This makes it possible to evaluate <strong>exact likelihoods</strong> and learn the model via <strong>maximum likelihood estimation (MLE)</strong>.</p>
<blockquote class="blockquote">
<p><strong>Note:</strong> Both <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{z}\)</span> must be continuous and have the same dimensionality since the transformation must be invertible.</p>
</blockquote>
</section>
<section id="a-flow-of-transformations" class="level2">
<h2 class="anchored" data-anchor-id="a-flow-of-transformations">A Flow of Transformations</h2>
<p>The term <em>flow</em> refers to the fact that we can compose multiple invertible functions to form a more expressive transformation:</p>
<p><span class="math display">\[
\mathbf{z}_m = f_\theta^{(m)} \circ f_\theta^{(m-1)} \circ \cdots \circ f_\theta^{(1)}(\mathbf{z}_0)
\]</span></p>
<p>In this setup: - <span class="math inline">\(\mathbf{z}_0 \sim p_Z\)</span> is sampled from a simple base distribution (e.g., standard Gaussian) - <span class="math inline">\(\mathbf{x} = \mathbf{z}_M\)</span> is the final transformed variable - The full transformation <span class="math inline">\(f_\theta\)</span> is the composition of all <span class="math inline">\(M\)</span> steps</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/e/e0/Normalizing-flow.svg" width="700" style="display: block; margin-left: auto; margin-right: auto;"></p>
<p><em>Figure: A normalizing flow transforms a simple distribution into a complex one using invertible transformations. (Adapted from Wikipedia)</em></p>
<p>The density of <span class="math inline">\(\mathbf{x}\)</span> is given by the change-of-variable formula:</p>
<p><span class="math display">\[
p_X(\mathbf{x}; \theta) = p_Z(f_\theta^{-1}(\mathbf{x})) \cdot \prod_{m=1}^M \left| \det \left( \frac{\partial (f_\theta^{(m)})^{-1}(\mathbf{z}_m)}{\partial \mathbf{z}_m} \right) \right|
\]</span></p>
<p>This approach allows the model to approximate highly complex distributions using simple building blocks.</p>
</section>
<section id="learning-and-inference" class="level2">
<h2 class="anchored" data-anchor-id="learning-and-inference">Learning and Inference</h2>
<p>Training a flow-based model is done by maximizing the log-likelihood over the dataset <span class="math inline">\(\mathcal{D}\)</span>:</p>
<p><span class="math display">\[
\max_\theta \log p_X(\mathcal{D}; \theta) = \sum_{\mathbf{x} \in \mathcal{D}} \log p_Z(f_\theta^{-1}(\mathbf{x})) + \log \left| \det \left( \frac{\partial f_\theta^{-1}(\mathbf{x})}{\partial \mathbf{x}} \right) \right|
\]</span></p>
<p><strong>Key advantages of normalizing flows:</strong></p>
<ul>
<li><strong>Exact likelihoods</strong>: No approximation needed â€” just apply the change-of-variable rule</li>
<li><strong>Efficient sampling</strong>: Generate new data by drawing <span class="math inline">\(\mathbf{z} \sim p_Z\)</span> and computing <span class="math inline">\(\mathbf{x} = f_\theta(\mathbf{z})\)</span></li>
<li><strong>Latent inference</strong>: Invert <span class="math inline">\(f_\theta\)</span> to compute latent codes <span class="math inline">\(\mathbf{z} = f_\theta^{-1}(\mathbf{x})\)</span>, without needing a separate encoder</li>
</ul>
</section>
<section id="computational-considerations" class="level2">
<h2 class="anchored" data-anchor-id="computational-considerations">Computational Considerations</h2>
<p>One challenge in training normalizing flow models is that computing the <strong>exact likelihood</strong> requires evaluating the <strong>determinant of the Jacobian matrix</strong> of the transformation:</p>
<ul>
<li>For a transformation <span class="math inline">\(f : \mathbb{R}^n \to \mathbb{R}^n\)</span>, the Jacobian is an <span class="math inline">\(n \times n\)</span> matrix.</li>
<li>Computing its determinant has a cost of <span class="math inline">\(\mathcal{O}(n^3)\)</span>, which is <strong>computationally expensive</strong> during training â€” especially in high dimensions.</li>
</ul>
<section id="key-insight" class="level3">
<h3 class="anchored" data-anchor-id="key-insight">Key Insight</h3>
<p>To make normalizing flows scalable, we design transformations where the <strong>Jacobian has a special structure</strong> that makes the determinant <strong>easy to compute</strong>.</p>
<p>For example: - If the Jacobian is a <strong>triangular matrix</strong>, the determinant is just the <strong>product of the diagonal entries</strong>, which can be computed in <span class="math inline">\(\mathcal{O}(n)\)</span> time. - This works because in a triangular matrix, all the off-diagonal elements are zero â€” so the determinant simplifies significantly.</p>
<p>In practice, flow models like <strong>RealNVP</strong> and <strong>MAF</strong> are designed so that each output dimension <span class="math inline">\(x_i\)</span> depends only on some subset of the input dimensions <span class="math inline">\(z_{\leq i}\)</span> (for lower triangular structure) or <span class="math inline">\(z_{\geq i}\)</span> (for upper triangular structure). This results in a Jacobian of the form:</p>
<p><span class="math display">\[
J = \frac{\partial \mathbf{f}}{\partial \mathbf{z}} =
\begin{pmatrix}
\frac{\partial f_1}{\partial z_1} &amp; 0 &amp; \cdots &amp; 0 \\
\ast &amp; \frac{\partial f_2}{\partial z_2} &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\ast &amp; \ast &amp; \cdots &amp; \frac{\partial f_n}{\partial z_n}
\end{pmatrix}
\]</span></p>
<p>Because of this triangular structure, computing the determinant becomes as simple as multiplying the diagonal terms:</p>
<p><span class="math display">\[
\det(J) = \prod_{i=1}^{n} \frac{\partial f_i}{\partial z_i}
\]</span></p>
<p>This is why many modern flow models rely on <strong>coupling layers</strong> or <strong>autoregressive masking</strong>: they preserve invertibility and enable efficient, exact likelihood computation.</p>
</section>
</section>
<section id="try-it-yourself" class="level2">
<h2 class="anchored" data-anchor-id="try-it-yourself">ðŸ§ª Try It Yourself</h2>
<p>You can explore a minimal PyTorch implementation of a normalizing flow model:</p>
<ul>
<li>ðŸ“˜ <a href="https://github.com/changezakram/Deep-Generative-Models/blob/main/normalizing_flow_pytorch.ipynb"><strong>View Notebook on GitHub</strong></a></li>
<li>ðŸš€ <a href="https://colab.research.google.com/github/changezakram/Deep-Generative-Models/blob/main/normalizing_flow_pytorch.ipynb"><strong>Run in Google Colab</strong></a></li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://deepgenerativemodels.github.io/notes/flow/"><strong>Deep Generative Models: Flow Notes</strong></a></li>
<li><a href="https://lilianweng.github.io/posts/2018-10-13-flow-models/?utm_source=chatgpt.com"><strong>Flow-based Deep Generative Models â€“ Lilian Weng</strong></a></li>
<li><a href="https://blog.evjang.com/2018/01/nf1.html"><strong>Normalizing Flows Tutorial â€“ Eric Jang, Part 1</strong></a></li>
<li><a href="https://blog.evjang.com/2018/01/nf2.html"><strong>Normalizing Flows Tutorial â€“ Eric Jang, Part 2</strong></a></li>
<li><a href="https://web.ma.utexas.edu/users/m408s/m408d/CurrentWeb/LM15-10-2.php"><strong>UT Austin: Change of Variable in One Dimension</strong></a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>