<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Variational Autoencoders – Deep Generative Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a14e3238c51140e99ccc48519b6ed9ce.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="styles.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Deep Generative Models</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Variational Autoencoders</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="autoencoders-vs-variational-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="autoencoders-vs-variational-autoencoders">Autoencoders vs Variational Autoencoders</h2>
<p>Traditional autoencoders learn to compress data into a lower-dimensional representation (latent space) and reconstruct it. However, they fall short in several areas:</p>
<ul>
<li>They lack <strong>generative capabilities</strong> — they cannot sample new data effectively</li>
<li>The <strong>latent space is unstructured</strong>, offering little control or interpretation</li>
<li>There is no <strong>probabilistic modeling</strong>, limiting uncertainty estimation</li>
</ul>
<p>Variational Autoencoders (VAEs) were introduced to overcome these limitations. Rather than encoding inputs into fixed latent vectors, VAEs learn a <strong>probabilistic latent space</strong> by modeling each input as a distribution — typically a Gaussian with a learned mean <span class="math inline">\(\\mu\)</span> and standard deviation <span class="math inline">\(\\sigma\)</span>. This approach enables the model to sample latent variables <span class="math inline">\(z\)</span> using the <strong>reparameterization trick</strong>, allowing the entire architecture to remain differentiable and trainable. By doing so, VAEs not only enable reconstruction, but also promote the learning of a <strong>continuous, interpretable latent space</strong> — a key enabler for generation and interpolation.</p>
<p>The diagram below illustrates this process:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Reparameterized_Variational_Autoencoder.png/960px-Reparameterized_Variational_Autoencoder.png" class="img-fluid"></p>
<p><em>Source: <a href="https://commons.wikimedia.org/wiki/File:Reparameterized_Variational_Autoencoder.png">Wikimedia Commons</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.</em></p>
</section>
<section id="probabilistic-framework" class="level2">
<h2 class="anchored" data-anchor-id="probabilistic-framework">Probabilistic Framework</h2>
<p>More formally, VAEs assume the data is generated by a two-step process:</p>
<ol type="1">
<li>Sample a latent variable <span class="math inline">\(\mathbf{z} \sim \mathcal{N}(0, I)\)</span></li>
<li>Generate the observation <span class="math inline">\(\mathbf{x}\)</span> from: <span class="math display">\[
p(\mathbf{x}|\mathbf{z}) = \mathcal{N}(\mu_\theta(\mathbf{z}), \Sigma_\theta(\mathbf{z}))
\]</span> where <span class="math inline">\(\mu_\theta\)</span> and <span class="math inline">\(\Sigma_\theta\)</span> are neural networks parameterized by <span class="math inline">\(\theta\)</span></li>
</ol>
<p>Here, <span class="math inline">\(\mathbf{z}\)</span> acts as a hidden or latent variable, which is <strong>unobserved during training</strong>. The model thus defines a — one for each <span class="math inline">\(\mathbf{z}\)</span>.</p>
<p>To compute the likelihood of a data point <span class="math inline">\(\mathbf{x}\)</span>, we must marginalize over all possible latent variables: <span class="math display">\[
  p(\mathbf{x}) = \int p(\mathbf{x}, \mathbf{z}) \, d\mathbf{z}
  \]</span></p>
<p>This integral requires integrating over all possible values of the latent variable <span class="math inline">\(\mathbf{z}\)</span>, which is often high-dimensional and enters the likelihood non-linearly through neural networks. Because of this, computing the marginal likelihood exactly is computationally intractable. This motivates the use of variational inference techniques like ELBO, which will be developed in the following sections.</p>
<section id="computational-challenge" class="level4">
<h4 class="anchored" data-anchor-id="computational-challenge">Computational Challenge</h4>
<p>This integral requires integrating over:</p>
<ul>
<li>All possible values of <span class="math inline">\(\mathbf{z}\)</span> (often high-dimensional)</li>
<li>Non-linear transformations through neural networks</li>
</ul>
<p><strong>Result:</strong> Exact computation is intractable, motivating variational inference techniques like ELBO (developed next).</p>
<hr>
</section>
</section>
<section id="estimating-the-marginal-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="estimating-the-marginal-likelihood">Estimating the Marginal Likelihood</h2>
<section id="naive-monte-carlo-estimation" class="level3">
<h3 class="anchored" data-anchor-id="naive-monte-carlo-estimation">Naive Monte Carlo Estimation</h3>
<p>One natural idea is to approximate the integral using samples from a simple distribution like the uniform distribution:</p>
<p><span class="math display">\[
p(x) \approx \frac{1}{K} \sum_{j=1}^K p_\theta(x, z_j), \quad z_j \sim \text{Uniform}
\]</span></p>
<p>However, this fails in practice. For most values of <span class="math inline">\(z\)</span>, the joint probability <span class="math inline">\(p_\theta(x, z)\)</span> is very low. Only a small region of the latent space contributes significantly to the integral. Since uniform sampling does not concentrate around these regions, the estimator has high variance and rarely “hits” likely values of <span class="math inline">\(z\)</span>.</p>
</section>
<section id="importance-sampling" class="level3">
<h3 class="anchored" data-anchor-id="importance-sampling">Importance Sampling</h3>
<p>To address this, we use <strong>importance sampling</strong>, introducing a proposal distribution <span class="math inline">\(q(z)\)</span>:</p>
<p><span class="math display">\[
p(x) = \mathbb{E}_{q(z)} \left[ \frac{p_\theta(x, z)}{q(z)} \right]
\]</span></p>
<p>This gives an <strong>unbiased estimator</strong> of <span class="math inline">\(p(x)\)</span> if <span class="math inline">\(q(z)\)</span> is well-chosen (ideally close to <span class="math inline">\(p_\theta(z|x)\)</span>). Intuitively, we sample <span class="math inline">\(z\)</span> more frequently in regions where <span class="math inline">\(p_\theta(x, z)\)</span> is high.</p>
<hr>
</section>
<section id="log-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="log-likelihood">Log likelihood</h3>
<p>Our goal is to optimize the <strong>log-likelihood</strong>, and the log of an expectation is not the same as the expectation of the log. That is,</p>
<p><span class="math display">\[
\log p(x) = log \mathbb{E}_{q(z)} \left[ \frac{p_\theta(x, z)}{q(z)} \right] \neq \mathbb{E}_{q(z)} \left[ \log \frac{p_\theta(x, z)}{q(z)} \right]
\]</span></p>
<p>While the marginal likelihood p(x) can be estimated unbiasedly using importance sampling, estimating its logarithm <span class="math inline">\(p(x)\)</span> introduces bias due to the concavity of the log function. This is captured by <strong>Jensen’s Inequality</strong>, which tells us:</p>
<p><span class="math display">\[
\log \mathbb{E}_{q(z)} \left[ \frac{p_\theta(x, z)}{q(z)} \right] \geq \underbrace{\mathbb{E}_{q(z)} \left[ \log \frac{p_\theta(x, z)}{q(z)} \right]}_{\text{ELBO}}
\]</span></p>
<p>This means that the <strong>expected log of the estimator underestimates the true log-likelihood</strong>. The right-hand side provides a tractable surrogate objective known as the <strong>Evidence Lower Bound (ELBO)</strong>, which is a biased lower bound to <span class="math inline">\(\log p(x)\)</span>.</p>
<p>This bias is inherent in variational approximations and reflects a trade-off between <strong>computational tractability</strong> and <strong>estimation accuracy</strong>. Optimizing the ELBO allows us to indirectly maximize the intractable log-likelihood.</p>
<p>In the next section, we formally derive this bound and explore its components in detail.</p>
<hr>
</section>
</section>
<section id="why-variational-inference" class="level2">
<h2 class="anchored" data-anchor-id="why-variational-inference">Why Variational Inference?</h2>
<p>Computing the true posterior distribution <span class="math inline">\(p(z|x)\)</span> is intractable in most cases because it requires evaluating the marginal likelihood over all possible values of z:</p>
<p><span class="math display">\[
p(x) = \int p(x, z) \, dz
\]</span></p>
<p>Variational inference tackles this by introducing a tractable, parameterized distribution <span class="math inline">\(q(z)\)</span> to approximate <span class="math inline">\(p(z|x)\)</span>. We aim to make <span class="math inline">\(q(z)\)</span> as close as possible to the true posterior by minimizing the KL divergence:</p>
<p><span class="math display">\[
D_{\text{KL}}(q(z) \| p(z|x))
\]</span></p>
<p>This turns inference into an optimization problem. A key result is the Evidence Lower Bound (ELBO). See next section.</p>
<hr>
</section>
<section id="training-a-vae" class="level2">
<h2 class="anchored" data-anchor-id="training-a-vae">Training a VAE</h2>
<section id="elbo-objective" class="level3">
<h3 class="anchored" data-anchor-id="elbo-objective">ELBO Objective</h3>
<p>Now that we’ve introduced the challenge of approximating the intractable posterior using variational inference, we turn our attention to deriving the Evidence Lower Bound (ELBO). This derivation reveals how optimizing a surrogate objective allows us to approximate the true log-likelihood of the data while keeping the approximate posterior close to the prior. The steps below walk through this formulation.</p>
<section id="step-1-kl-divergence-objective" class="level5">
<h5 class="anchored" data-anchor-id="step-1-kl-divergence-objective">Step 1: KL Divergence Objective</h5>
<p><span class="math display">\[\begin{equation}
D_{KL}(q(z)\|p(z|x; \theta)) = \sum_z q(z) \log \frac{q(z)}{p(z|x; \theta)}
\end{equation}\]</span></p>
</section>
<section id="step-2-apply-bayes-rule" class="level5">
<h5 class="anchored" data-anchor-id="step-2-apply-bayes-rule">Step 2: Apply Bayes’ Rule</h5>
<p>Substitute <span class="math inline">\(p(z|x; \theta) = \frac{p(z,x;\theta)}{p(x;\theta)}\)</span>: <span class="math display">\[\begin{equation}
= \sum_z q(z) \log \left( \frac{q(z) \cdot p(x; \theta)}{p(z, x; \theta)} \right)
\end{equation}\]</span></p>
</section>
<section id="step-3-decompose-terms" class="level5">
<h5 class="anchored" data-anchor-id="step-3-decompose-terms">Step 3: Decompose Terms</h5>
<p><span class="math display">\[\begin{align}
&amp;= \sum_z q(z) \log q(z) + \sum_z q(z) \log p(x; \theta) \nonumber \\
&amp;\quad - \sum_z q(z) \log p(z, x; \theta) \\
&amp;= -H(q) + \log p(x; \theta) - \mathbb{E}_q[\log p(z,x;\theta)]
\end{align}\]</span></p>
<blockquote class="blockquote">
<p><strong>Note:</strong> The term <span class="math inline">\(\mathcal{H}(q)\)</span> represents the <strong>entropy</strong> of the variational distribution <span class="math inline">\(q(z|x)\)</span>. Entropy is defined as:</p>
<p><span class="math display">\[
\mathcal{H}(q) = -\sum_z q(z) \log q(z) = -\mathbb{E}_{q(z)}[\log q(z)]
\]</span></p>
<p>Entropy measures the amount of uncertainty or “spread” in a distribution. A high-entropy <span class="math inline">\(q(z)\)</span> places probability mass across a wide region of the latent space, while a low-entropy <span class="math inline">\(q(z)\)</span> is more concentrated. This decomposition is key to understanding the KL divergence term in the ELBO.</p>
</blockquote>
</section>
<section id="step-4-rearrange-for-elbo" class="level5">
<h5 class="anchored" data-anchor-id="step-4-rearrange-for-elbo">Step 4: Rearrange for ELBO</h5>
<p><span class="math display">\[
\log p(x; \theta) =
\underbrace{
    \mathbb{E}_q[\log p(z, x; \theta)] + \mathcal{H}(q)
}_{\text{ELBO}}
+D_{KL}(q(z)\|p(z|x; \theta))
\]</span></p>
<p>This equation shows that the log-likelihood <span class="math inline">\(\log p(x)\)</span> can be decomposed into the ELBO and the KL divergence between the approximate posterior and the true posterior. Since the KL divergence is always non-negative, the ELBO serves as a lower bound to the log-likelihood. By maximizing the ELBO, we indirectly minimize the KL divergence, bringing <span class="math inline">\(q(z)\)</span> closer to <span class="math inline">\(p(z|x)\)</span>.</p>
<p><img src="https://deepgenerativemodels.github.io/notes/vae/klgap.png" class="img-fluid"> <em>Visualizing how <span class="math inline">\(\log p(x)\)</span> decomposes into the ELBO and KL divergence.</em><br>
Source: <a href="https://deepgenerativemodels.github.io/notes/vae/">deepgenerativemodels.github.io</a></p>
</section>
<section id="key-results" class="level5">
<h5 class="anchored" data-anchor-id="key-results">Key Results</h5>
<ol type="1">
<li><p><strong>Evidence Lower Bound (ELBO)</strong>: <span class="math display">\[\begin{equation}
\mathcal{L}(\theta,\phi) = \mathbb{E}_{q(z;\phi)}[\log p(x,z;\theta)] + H(q(z;\phi))
\end{equation}\]</span></p></li>
<li><p><strong>Optimization</strong>: <span class="math display">\[\begin{equation}
\max_{\theta,\phi} \mathcal{L}(\theta,\phi) \Rightarrow
\begin{cases}
\text{Maximizes data likelihood} \\
\text{Minimizes } D_{KL}(q\|p)
\end{cases}
\end{equation}\]</span></p></li>
</ol>
</section>
</section>
</section>
<section id="understanding-the-kl-divergence-term-in-the-vae-loss" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-kl-divergence-term-in-the-vae-loss">Understanding the KL Divergence Term in the VAE Loss</h2>
<p>In a VAE, the KL divergence term <strong>penalizes the encoder</strong> for producing latent distributions that deviate too far from the standard normal prior. This regularization has several important benefits:</p>
<ul>
<li>It ensures that the latent space has a <strong>consistent structure</strong>, enabling meaningful sampling and interpolation.</li>
<li>It helps avoid <strong>large gaps between clusters</strong> in latent space by encouraging the encoder to distribute representations more uniformly.</li>
<li>It pushes the model to use the space around the origin more symmetrically and efficiently.</li>
</ul>
<section id="balancing-kl-divergence-and-reconstruction" class="level3">
<h3 class="anchored" data-anchor-id="balancing-kl-divergence-and-reconstruction">Balancing KL Divergence and Reconstruction</h3>
<p>In a Variational Autoencoder, the loss balances two goals:</p>
<ol type="1">
<li><strong>Reconstruction</strong> — making the output resemble the input</li>
<li><strong>Regularization</strong> — keeping the latent space close to a standard normal distribution</li>
</ol>
<p>This is captured by the loss function:</p>
<p><span class="math display">\[
\mathcal{L}_{\text{VAE}} = \text{Reconstruction Loss} + \beta \cdot D_{\text{KL}}(q(z|x) \,\|\, p(z))
\]</span></p>
<p>The parameter <span class="math inline">\(\beta\)</span> controls how strongly we enforce this regularization. Getting its value right is critical.</p>
<section id="when-beta-is-too-low" class="level4">
<h4 class="anchored" data-anchor-id="when-beta-is-too-low">When <span class="math inline">\(\beta\)</span> is too low:</h4>
<ul>
<li>The model mostly ignores the KL term, behaving like a plain autoencoder</li>
<li>The latent space becomes disorganized or fragmented</li>
<li>Sampling from the prior <span class="math inline">\(p(z) = \mathcal{N}(0, I)\)</span> results in <strong>unrealistic or broken outputs</strong></li>
</ul>
</section>
<section id="when-beta-is-too-high" class="level4">
<h4 class="anchored" data-anchor-id="when-beta-is-too-high">When <span class="math inline">\(\beta\)</span> is too high:</h4>
<ul>
<li>The encoder is forced to keep <span class="math inline">\(q(z|x)\)</span> too close to the prior</li>
<li>It encodes less information about the input</li>
<li>Reconstructions become <strong>blurry or generic</strong>, since the decoder gets little to work with</li>
</ul>
<blockquote class="blockquote">
<p><strong>Choosing <span class="math inline">\(\beta\)</span> carefully is essential for balancing generalization and fidelity.</strong><br>
A well-tuned <span class="math inline">\(\beta\)</span> helps the VAE both reconstruct accurately and generate new samples that resemble the training data.</p>
</blockquote>
</section>
</section>
<section id="gradient-challenge" class="level3">
<h3 class="anchored" data-anchor-id="gradient-challenge">Gradient Challenge</h3>
<p>In variational inference, we approximate the true posterior <span class="math inline">\(p(z|x)\)</span> with a tractable distribution <span class="math inline">\(q_\phi(z|x)\)</span>. This allows us to optimize the ELBO:</p>
<p><span class="math display">\[
\mathcal{L}(x; \theta, \phi) = \mathbb{E}_{q_\phi(z|x)}\left[\log p_\theta(x, z) - \log q_\phi(z|x)\right]
\]</span></p>
<p>Our goal is to maximize this objective with respect to both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>. While computing the gradient with respect to <span class="math inline">\(\theta\)</span> is straightforward, optimizing with respect to <span class="math inline">\(\phi\)</span> presents a challenge.</p>
<p>The complication arises because <span class="math inline">\(\phi\)</span> appears both in the density <span class="math inline">\(q_\phi(z|x)\)</span> and in the expectation operator. That is:</p>
<p><span class="math display">\[
\nabla_\phi \mathbb{E}_{q_\phi(z|x)} \left[\log p_\theta(x, z) - \log q_\phi(z|x)\right]
\]</span></p>
<p>This gradient is hard to compute directly because we’re sampling from a distribution that depends on the parameters we’re trying to update.</p>
<hr>
</section>
<section id="the-reparameterization-trick" class="level3">
<h3 class="anchored" data-anchor-id="the-reparameterization-trick">The Reparameterization Trick</h3>
<p>To make this expression differentiable, we <strong>reparameterize</strong> the random variable <span class="math inline">\(z\)</span> as a deterministic transformation of a parameter-free noise variable <span class="math inline">\(\epsilon\)</span>:</p>
<p><span class="math display">\[
\epsilon \sim \mathcal{N}(0, I), \quad z = \mu_\phi(x) + \sigma_\phi(x) \cdot \epsilon
\]</span></p>
<p>This turns the expectation into:</p>
<p><span class="math display">\[
\mathbb{E}_{\epsilon \sim \mathcal{N}(0, I)}\left[\log p_\theta(x, z) - \log q_\phi(z|x)\right]
\]</span></p>
<p>where <span class="math inline">\(z\)</span> is now a differentiable function of <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\epsilon\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Reparameterization_Trick.png/600px-Reparameterization_Trick.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Reparameterization Trick Diagram</figcaption>
</figure>
</div>
<p><em>Image source: <a href="https://en.wikipedia.org/wiki/File:Reparameterization_Trick.png">Wikipedia (CC BY-SA 4.0)</a></em></p>
<p>This diagram illustrates how the reparameterization trick enables <strong>differentiable sampling</strong>:</p>
<ul>
<li>In the <strong>original formulation</strong>, ( z ) is sampled directly from a learned distribution, breaking the gradient flow.</li>
<li>In the <strong>reparameterized formulation</strong>, we sample noise ( (0, I) ), and compute ( z = + ), making the sampling path fully differentiable.</li>
</ul>
<section id="monte-carlo-approximation" class="level4">
<h4 class="anchored" data-anchor-id="monte-carlo-approximation">Monte Carlo Approximation</h4>
<p>We approximate the expectation using Monte Carlo sampling:</p>
<p><span class="math display">\[
\mathbb{E}_{\epsilon}[\log p_\theta(x, z) - \log q_\phi(z|x)] \approx \frac{1}{K} \sum_{k=1}^K \left[\log p_\theta(x, z^{(k)}) - \log q_\phi(z^{(k)}|x)\right]
\]</span></p>
<p>with:</p>
<p><span class="math display">\[
z^{(k)} = \mu_\phi(x) + \sigma_\phi(x) \cdot \epsilon^{(k)}, \quad \epsilon^{(k)} \sim \mathcal{N}(0, I)
\]</span></p>
<p>This enables us to compute gradients using backpropagation.</p>
<hr>
</section>
<section id="summary" class="level4">
<h4 class="anchored" data-anchor-id="summary">Summary</h4>
<ul>
<li>Variational inference introduces a gradient challenge because <span class="math inline">\(q_\phi(z|x)\)</span> depends on <span class="math inline">\(\phi\)</span></li>
<li>The reparameterization trick expresses <span class="math inline">\(z\)</span> as a differentiable function of noise and <span class="math inline">\(\phi\)</span></li>
<li>This allows us to use backpropagation to optimize the ELBO efficiently</li>
</ul>
<hr>
</section>
</section>
<section id="amortized-inference" class="level3">
<h3 class="anchored" data-anchor-id="amortized-inference">Amortized Inference</h3>
<p>In classical variational inference, we introduce a separate set of variational parameters <span class="math inline">\(\phi^i\)</span> for each datapoint <span class="math inline">\(x^i\)</span> to approximate the true posterior <span class="math inline">\(p(z|x^i)\)</span>. However:</p>
<blockquote class="blockquote">
<p>Optimizing a separate <span class="math inline">\(\phi^i\)</span> for every datapoint is computationally expensive and does not scale to large datasets.</p>
</blockquote>
<hr>
<section id="the-key-idea-amortization" class="level4">
<h4 class="anchored" data-anchor-id="the-key-idea-amortization">The Key Idea: Amortization</h4>
<p>Instead of learning and storing a separate <span class="math inline">\(\phi^i\)</span> for every datapoint, we learn a <strong>single parametric function</strong> <span class="math inline">\(f_\phi(x)\)</span> — typically a neural network — that maps each input <span class="math inline">\(x\)</span> to the parameters of the approximate posterior:</p>
<p><span class="math display">\[
q_\phi(z|x) = \mathcal{N}\left(\mu_\phi(x), \sigma^2_\phi(x)\right)
\]</span></p>
<p>Here, <span class="math inline">\(\phi\)</span> are the shared parameters of the encoder network, and <span class="math inline">\(\mu_\phi(x), \sigma_\phi(x)\)</span> are its outputs.</p>
<p>This is like learning a regression function that predicts the optimal variational parameters for any input <span class="math inline">\(x\)</span>.</p>
<hr>
</section>
</section>
<section id="training-with-amortized-inference" class="level3">
<h3 class="anchored" data-anchor-id="training-with-amortized-inference">Training with Amortized Inference</h3>
<p>Our training objective remains the ELBO:</p>
<p><span class="math display">\[
\mathcal{L}(x; \theta, \phi) = \mathbb{E}_{q_\phi(z|x)}\left[\log p_\theta(x, z) - \log q_\phi(z|x)\right]
\]</span></p>
<p>We optimize both <span class="math inline">\(\theta\)</span> (decoder parameters) and <span class="math inline">\(\phi\)</span> (encoder parameters) using stochastic gradient descent.</p>
<section id="algorithm" class="level4">
<h4 class="anchored" data-anchor-id="algorithm">Algorithm:</h4>
<ol type="1">
<li><p><strong>Initialize</strong> <span class="math inline">\(\theta^{(0)}, \phi^{(0)}\)</span></p></li>
<li><p>Sample a datapoint <span class="math inline">\(x^i\)</span></p></li>
<li><p>Use <span class="math inline">\(f_\phi(x^i)\)</span> to produce <span class="math inline">\(\mu^i, \sigma^i\)</span></p></li>
<li><p>Sample <span class="math inline">\(z^i = \mu^i + \sigma^i \cdot \epsilon\)</span>, with <span class="math inline">\(\epsilon \sim \mathcal{N}(0, I)\)</span></p></li>
<li><p>Estimate the ELBO and compute gradients w.r.t. <span class="math inline">\(\theta, \phi\)</span></p></li>
<li><p>Update <span class="math inline">\(\theta, \phi\)</span> using gradient descent</p></li>
<li><p>Update <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\phi\)</span> using gradient descent:</p></li>
</ol>
<p><span class="math display">\[
\phi \leftarrow \phi + \tilde{\nabla}_\phi \sum_{x \in \mathcal{B}} \text{ELBO}(x; \theta, \phi)
\]</span></p>
<p><span class="math display">\[
\theta \leftarrow \theta + \tilde{\nabla}_\theta \sum_{x \in \mathcal{B}} \text{ELBO}(x; \theta, \phi)
\]</span></p>
<p>where <span class="math inline">\(\mathcal{B}\)</span> is the current minibatch and <span class="math inline">\(\tilde{\nabla}\)</span> indicates a stochastic gradient approximation.</p>
<hr>
</section>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<ul>
<li>Amortized inference replaces per-datapoint optimization with a single learned mapping <span class="math inline">\(f_\phi(x)\)</span></li>
<li>This makes variational inference scalable and efficient</li>
<li>The model can generalize to unseen inputs by predicting variational parameters on-the-fly</li>
</ul>
<blockquote class="blockquote">
<p><strong>Note:</strong> Following common practice in the literature, we use <span class="math inline">\(\phi\)</span> to denote the parameters of the encoder network, even though it now defines a function rather than individual variational parameters.</p>
</blockquote>
<hr>
</section>
</section>
<section id="applications-of-vaes" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-vaes">Applications of VAEs</h2>
<p>Variational Autoencoders are widely used in:</p>
<ul>
<li><strong>Image Generation</strong>: VAEs can generate new images similar to the training data (e.g., MNIST digits)<br>
</li>
<li><strong>Anomaly Detection</strong>: High reconstruction error flags unusual data points<br>
</li>
<li><strong>Representation Learning</strong>: Latent space captures features for downstream tasks</li>
</ul>
<section id="face-generation-with-convolutional-vae" class="level3">
<h3 class="anchored" data-anchor-id="face-generation-with-convolutional-vae">😎 Face Generation with Convolutional VAE</h3>
<p>A convolutional VAE trained on the CelebA dataset.<br>
Learn how to generate realistic faces from latent samples.</p>
<p><a href="https://colab.research.google.com/github/changezakram/Deep-Generative-Models/blob/main/vae_faces.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Colab"></a><br>
📓 <a href="https://github.com/changezakram/Deep-Generative-Models/blob/main/vae_faces.ipynb">View on GitHub</a> —</p>
</section>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further Reading</h2>
<p>For readers interested in diving deeper into the theory and applications of variational autoencoders, the following resources are recommended:</p>
<ul>
<li><p><strong>Tutorial on Variational Autoencoders</strong><br>
<em>Carl Doersch</em> (2016)<br>
<a href="https://arxiv.org/pdf/1606.05908">https://arxiv.org/pdf/1606.05908</a></p></li>
<li><p><strong>Auto-Encoding Variational Bayes</strong><br>
<em>Kingma &amp; Welling</em> (2014) — the original VAE paper<br>
<a href="https://arxiv.org/pdf/1312.6114">https://arxiv.org/pdf/1312.6114</a></p></li>
<li><p><strong>The Challenges of Amortized Inference for Structured Prediction</strong><br>
<em>Cremer, Li, &amp; Duvenaud</em> (2019)<br>
<a href="https://arxiv.org/pdf/1906.02691">https://arxiv.org/pdf/1906.02691</a></p></li>
<li><p><strong>Deep Generative Models course notes</strong><br>
<a href="https://deepgenerativemodels.github.io/notes/vae/">https://deepgenerativemodels.github.io/notes/vae/</a></p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>