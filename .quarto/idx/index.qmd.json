{"title":"Deep Generative Models","markdown":{"yaml":{"title":"Deep Generative Models"},"headingText":"Evolution of AI Capabilities","containsRefs":false,"markdown":"\n\n\nAI has changed a lot over the past few decades. We've gone from simple rule-based systems to creative generative models, and now to AI that can plan and act on its own. Each stage brought new capabilities but also new challenges. To understand where we are today, it helps to look at these three types: Traditional AI, Generative AI, and Agentic AI.\n\n**AI paradigms**\n\n**Traditional AI** follows fixed rules and is great at repetitive tasks like sorting emails or detecting fraud. **Generative AI** can create new things—write text, generate images, or write code—by learning patterns from lots of data. **Agentic AI** goes even further: it can plan ahead, reason through problems, and handle multi-step tasks without much human help.\nHere's how they compare:\n\n\n<div style=\"overflow-x:auto;\">\n\n| Capability            | **Traditional AI**<br><small>Rule-driven tools</small> | **Generative AI**<br><small>Smart assistants</small> | **Agentic AI**<br><small>Autonomous actors</small> |\n|-----------------------|---------------------------------------------|--------------------------------------------|--------------------------------------------|\n| **What it does**      | Follows hard-coded logic and rules          | Understands prompts and generates output   | Plans, reasons, and acts across steps       |\n| **How it behaves**    | Rigid, predictable                          | Creative but guided                        | Goal-seeking and adaptive                   |\n| **Human involvement** | Fully manual setup and supervision          | Needs context and oversight                | Can operate independently (with guardrails) |\n| **Strengths**         | Reliable on structured tasks                | Great at summarizing, drafting, generating | Handles multistep workflows                 |\n| **Best used for**     | Repetitive decisions and automation         | Insight generation and copiloting          | Full process orchestration                  |\n\n</div>\n\nTraditional AI needs constant human direction. Generative AI acts more like a smart assistant. Agentic AI can work toward goals on its own, though it still needs guardrails. This evolution creates exciting opportunities, but it also raises important questions about safety and control.\n\nLet's explore why generative AI has become such a big deal.\n\n---\n\n## Why Generative AI Matters\n\nGenerative AI can create brand new content—text, images, code, you name it—by learning patterns from existing data. Unlike traditional AI that just sorts or labels things, generative models actually produce something new. Since 2022, this field has exploded. Models like ChatGPT, Claude, and Gemini are being used everywhere—from helping people write and create images to detecting fraud and generating synthetic data for testing.\n\n> **Business impact:** McKinsey estimates that generative AI could contribute up to **$4.4 trillion in annual global economic value**, with wide-ranging implications for productivity, personalization, and decision support.\n\nBut it's not all upside. GenAI can produce outputs that sound convincing but are completely wrong, biased, or even harmful. This is especially risky in fields like banking, healthcare, and law where mistakes have serious consequences. Making GenAI work responsibly means having strong governance, keeping humans in the loop, and deploying it ethically.\n\n---\n\n## How Generative Models Work\n\nNow that we've seen why GenAI matters, let's look under the hood. How do these models actually learn to create realistic content? The basic idea is pretty simple. These models look at tons of real examples—dog photos, text, whatever—and figure out the patterns. Then they use those patterns to make new stuff that looks real.\n\n![**Figure 1:** Generative models learn to approximate the true data distribution $P_{\\text{data}}$ by optimizing a parameterized model $P_\\theta$. The goal is to minimize divergence $d(P_{\\text{data}}, P_\\theta)$. *Source: Adapted from Stanford CS236.*](images/gen-ai.png)\n\nHere's what's going on under the hood:\n\nReal data has patterns. Dog photos usually have four legs, fur, a tail. We call this the data distribution $P_{\\text{data}}$. The model tries to learn this pattern by building its own version, called $P_\\theta$ (where $\\theta$ represents the model's internal settings).\n\nTraining means adjusting those settings until the model's distribution $P_\\theta$ matches the data distribution $P_{\\text{data}}$. The model keeps tweaking itself to minimize the gap between what it generates and what actually exists. Once trained, you can generate new content by sampling from what the model learned.\n\nThe basics:\n\n- The model learns a pattern $P_\\theta$ that captures what makes data look real\n- New content comes from sampling—drawing examples from this learned pattern\n- Training means making $P_\\theta$ match the real data pattern as closely as possible\n\n**Different models, different approaches:**\n\nDifferent types of models use different techniques to learn these patterns:\n\n- Autoregressive models (like GPT) and Normalizing Flows directly maximize how likely the real data is under their model\n- VAEs use a workaround called ELBO (Evidence Lower Bound) to approximate this\n- GANs pit two networks against each other—one creates fakes, the other spots them—until the fakes become incredibly convincing\n- Diffusion models and EBMs use techniques like score matching to learn the patterns\n\nThe key insight: all these models are trying to learn \"what real data looks like\" so they can create convincing new examples. They just take different paths to get there.\n\n---\n\n## How We Got Here\n\nTo understand today's AI, it helps to look back at the key breakthroughs that got us here. The timeline below shows how Generative AI evolved over five distinct periods:\n\n![**Figure:** Generative AI: Key Milestones. Tracks key advances from early neural nets and probabilistic models to modern transformers, diffusion models, and real-world deployment.](images/ai-timeline.png)\n\nEach era built on what came before, introducing new techniques and expanding what AI could do. Let's walk through each one.\n\n**1980–1990s: Early Foundations**\n\nIn the late 1980s, researchers introduced Recurrent Neural Networks (RNNs), which could process sequences of data like sentences or time series. LSTMs came in 1997, making it easier for models to remember context over longer sequences. Around the same time, early generative models started appearing—a shift from AI that just classified things to AI that could actually create new content. Probabilistic models like Bayesian networks and Hidden Markov Models gave us ways to model uncertainty and complex patterns. These weren't exciting, but they laid the groundwork for everything that followed.\n\n**2000s: Learning Better Representations**\n\nThe 2000s saw neural networks make a comeback. Researchers figured out how to train them to learn meaningful features from raw data automatically—no hand-crafted rules needed. The big breakthrough was Deep Belief Networks in 2006. They used a clever training trick called layer-wise pretraining that made deep learning practical again after years of disappointing results. This proved that neural networks could learn hierarchical patterns on their own, which opened the door to modern deep learning.\n\n**2010s: The Big Leap**\n\nThis decade brought the models that most people think of as \"modern AI.\" VAEs showed up in 2013 and GANs in 2014-both could generate realistic images and learn useful representations. Then came Transformers in 2017, which changed everything for language models. Their self-attention mechanism made it possible to build the large language models we use today. Diffusion models appeared in 2015 too, though they didn't work well until around 2020-2022. Together, these architectures created the foundation for the AI boom we're seeing now.\n\n**2020–2022: Going Big**\n\nGPT-3 launched in 2020 and DALL-E 2 in 2022, showing what massive models trained on huge datasets could do—write coherent essays, generate photorealistic images, you name it. Models got better at zero-shot and few-shot learning, meaning they could handle new tasks without needing specific training for each one. We also saw multimodal models that could work with text, images, and audio all at once. Diffusion models matured during this time too, often producing better images than GANs. This was when GenAI went from a research topic to something people could actually use.\n\n**2023–2025: Real-World Deployment**\n\nOpen-source models like LLaMA and Mistral made powerful AI accessible to more people, not just big tech companies with massive budgets. This competition sped up innovation. Tools like LangChain and RAG emerged to help AI systems do more complex, multi-step tasks and ground their outputs in real data. Companies started deploying GenAI in production, which meant they had to get serious about governance, safety, and making sure these systems were explainable and trustworthy. We're moving from \"cool demos\" to \"systems people rely on,\" which changes what matters.\n\nNow that we've seen how GenAI evolved, let's dive deeper into the main types of models. Each family has its own way of learning patterns and generating new content.\n\n---\n\n## Key Gen AI Model Families\n\nThese foundational architectures form the backbone of modern GenAI applications. Each family differs in how it models data distributions, handles sampling and inference, and supports various real-world use cases.\n\n### Variational Autoencoders (VAEs)\n- **Core Idea**: Encode input into a latent space and reconstruct while optimizing a lower bound on likelihood (ELBO).\n- **Likelihood**: Approximate (variational lower bound).\n- **Sampling**: Fast — sample latent vector and decode.\n- **Use Cases**: Representation learning, image generation.\n- **Example Models**: β-VAE, Conditional VAE  \n- [Go to VAE Models →](vae.qmd)\n\n### Autoregressive Models\n- **Core Idea**: Factor the joint distribution as a product of conditional probabilities.\n- **Likelihood**: Exact.\n- **Sampling**: Slow — token-by-token generation.\n- **Use Cases**: Language modeling, code generation, time series.\n- **Example Models**: GPT, PixelRNN  \n- [Go to Autoregressive Models →]\n\n### Normalizing Flows\n- **Core Idea**: Learn invertible transformations using the change-of-variable formula.\n- **Likelihood**: Exact and tractable.\n- **Sampling**: Fast — sample from base distribution and invert.\n- **Use Cases**: Density estimation, latent space modeling.\n- **Example Models**: RealNVP, Glow  \n- [Go to Flow Models →](flows.qmd)\n\n### Energy-Based Models (EBMs)\n- **Core Idea**: Define an energy function over inputs; lower energy = higher probability.\n- **Likelihood**: Unnormalized (intractable partition function).\n- **Sampling**: Very slow — requires MCMC or Langevin dynamics.\n- **Use Cases**: Uncertainty modeling, compositional generation.\n- **Example Models**: Score-based EBMs  \n- [Go to EBMs →](ebm.qmd)\n\n### Generative Adversarial Networks (GANs)\n- **Core Idea**: Generator and discriminator compete in a minimax game to produce realistic samples.\n- **Likelihood**: None (implicit model).\n- **Sampling**: Fast — sample latent vector and pass through generator.\n- **Use Cases**: High-quality image generation, style transfer.\n- **Example Models**: StyleGAN, CycleGAN  \n- [Go to GAN Models →]\n\n### Diffusion Models\n- **Core Idea**: Learn to reverse a gradual noise process via denoising.\n- **Likelihood**: Approximate (via variational bound).\n- **Sampling**: Slow — requires hundreds of reverse steps.\n- **Use Cases**: High-resolution image and audio generation.\n- **Example Models**: Stable Diffusion  \n- [Go to Diffusion Models →](diffusion.qmd)\n\n\n::: {.callout-tip title=\"Explore Related Topics\"}\nExpand your understanding of Generative AI with these supporting deep dives:\n\n- [Transformers →](transformers.qmd)  \n  Understand the self-attention architecture behind modern LLMs and Gen AI models.\n\n- [Post-Training Techniques →](post-training.qmd)  \n  Learn how fine-tuning, RLHF, and instruction tuning make base models usable in the real world.\n\n- [Evaluation Strategies →](nlp-eval.qmd)  \n  Discover how we evaluate GenAI output quality — from traditional metrics to modern LLM-based approaches.\n:::\n\n---\n\n## Use-Case Framing & Prioritization\n\nBefore diving into specific industry use cases, it's critical to assess *where* and *how* generative AI can deliver real value. Not every idea is equally feasible, impactful, or low-risk. A structured framing process helps ensure that AI initiatives align with business priorities and responsible innovation.\n\nWe recommend evaluating GenAI use cases across three key dimensions:\n\n- **Business Value**: Consider how the use case impacts revenue generation, cost reduction, operational efficiency, risk mitigation, or customer experience. This ensures alignment with strategic business outcomes.\n\n- **Feasibility**: Evaluate the availability and quality of data, the readiness of models, the complexity of integration, and infrastructure or compute requirements. This grounds ideas in technical and operational reality.\n\n- **Governance Sensitivity**: Assess how much oversight is needed to meet regulatory, ethical, or reputational expectations—especially in domains like banking and healthcare. This includes explainability, auditability, and the potential for misuse.\n\nThis framing helps prioritize AI use cases that are not only **promising**, but also **implementable** and **sustainable**—especially in highly regulated environments.\n\n---\n\n## Industry Use Cases\n\nGenAI is being deployed across industries in two ways: **horizontal use cases** that work everywhere, and **industry-specific applications** tailored to particular sectors. Let's look at both.\n\n### Horizontal Use Cases (Apply Across Industries)\n\nThese use cases work in nearly any industry—they're about common business functions like content creation, customer service, and compliance.\n\n| **Use Case**             | **What It Does**                                                                 | **Business Impact**                                                                |\n|--------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|\n| **Content Generation**   | Creates reports, emails, social media posts                              | Scale content marketing efforts without proportional headcount increases           |\n| **Personalized Marketing** | Generates customized emails, landing pages, and social posts                  | Reach target audiences more effectively and increase conversion rates              |\n| **Customer Service**     | Powers chatbots that answer questions and resolve problems                       | Free up human agents to focus on complex issues                                    |\n| **Risk Management**      | Identifies and predicts fraud, cyberattacks, supply chain disruptions            | Mitigate risks and protect assets before problems occur                            |\n| **Compliance**           | Generates compliant documents like contracts, reports, disclosures               | Save time and money while reducing noncompliance risk                              |\n| **Software Development** | Generates code, provides snippets, documents and refactors code                  | Speed up development, reduce errors, generate test cases                           |\n| **Data Augmentation**    | Creates synthetic data when real data is insufficient                            | Enable model training when privacy or scarcity limits real data availability       |\n| **Contract Management**  | Drafts legal documents and understands regulatory requirements                   | Reduce human mistakes and make informed decisions faster                           |\n\n\n### Banking & Financial Services\n\nFinancial institutions use GenAI for scenario modeling, risk assessment, and customer operations—all while navigating strict regulatory requirements.\n\n| **Use Case**                   | **Example Application**                                                                 |\n|--------------------------------|------------------------------------------------------------------------------------------|\n| **Customer Service**           | Virtual agents for handling account queries and FAQs                                     |\n| **Fraud Detection**            | Real-time anomaly detection in transaction behavior                                      |\n| **Risk Modeling**              | Scenario analysis for credit risk and market stress testing                              |\n| **Operational Efficiency**     | Auto-summarizing calls and processing back-office documents                              |\n| **Business Intelligence**      | Spotting unusual patterns in product or branch-level KPIs                                |\n| **Marketing & Personalization**| Creating personalized offers based on customer behavior and transaction history          |\n| **Product Development**        | Simulating scenarios to develop new financial products and services                      |\n\n**What makes financial services different:**  \nDecision-making requires scenario simulation, risk model assessment, and customer personalization based on transaction history. Everything must be explainable and auditable for regulators.\n\n> Real-world examples from JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley.  \n> **[View complete banking implementation guide →](gen-ai-use-cases/banking-use-cases.html)**\n\n---\n\n### Healthcare & Life Sciences\n\nHealthcare organizations deploy GenAI for drug discovery, clinical documentation, and personalized treatment—all while maintaining patient privacy and safety standards.\n\n| **Use Case**              | **Example Application**                                                                      |\n|---------------------------|-----------------------------------------------------------------------------------------------|\n| **Clinical Documentation**| Auto-generating visit summaries and physician notes                                           |\n| **Drug Discovery**        | Accelerating compound generation and molecular simulation                                     |\n| **Medical Device Design** | Creating and optimizing new medical devices                                                   |\n| **Treatment Plans**       | Generating personalized patient treatment plans                                               |\n| **Medical Imaging**       | Improving and reconstructing radiological images                                              |\n| **Diagnostics & Triage**  | Supporting diagnosis with uncertainty-aware modeling (confidence scores)                      |\n| **Patient Education**     | Explaining test results, medication instructions, and drug interactions in plain language     |\n\n**What makes healthcare different:**  \nGenAI develops new drugs and treatments, designs medical devices, creates personalized treatment plans, and generates patient documentation on instructions, risks, and drug interactions. Patient safety and privacy (HIPAA) are non-negotiable.\n\n> Examples from Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine.  \n> **[View complete healthcare implementation guide →](gen-ai-use-cases/healthcare-use-cases.html)**\n\n---\n\n## Governance & Risk Warnings\n\nGenerative AI introduces exciting new capabilities—but also carries **unique risks** that traditional analytics and rules-based systems did not. Without strong governance, these risks can quickly undermine trust, compliance, and effectiveness.\n\n**Key Risks to Watch:**\n\n- **Inaccuracy & Hallucination**: GenAI can confidently generate responses that sound right—but are completely wrong or misleading.\n- **Bias & Fairness**: Models can unintentionally reinforce historical bias found in training data. These outcomes could affect customers or patients.\n- **Security & Privacy**: Prompts or training data may inadvertently expose sensitive, private, or proprietary information.\n- **Overtrust**: Users may take outputs at face value without critical thinking, especially in high-volume environments like BI dashboards or chatbots.\n- **Regulatory Exposure**: Lack of transparency, explainability, or auditability may put the organization at odds with standards such as OCC guidelines, HIPAA, GDPR, or emerging AI laws.\n\n**Governance Practices to Put in Place:**\n\n- **Human-in-the-Loop (HITL)**: Require review and validation for GenAI-generated content in regulated or customer-facing contexts.\n- **Explainability & Traceability**: Where possible, use interpretable model frameworks, or add metadata like model version, confidence score, or decision path.\n- **Prompt & Output Logging**: Maintain logs of GenAI usage for auditing, debugging, and continuous refinement.\n- **Access Control & Masking**: Limit who can access GenAI systems and ensure sensitive data is redacted before prompt injection or model training.\n- **Alignment with Ethical and Regulatory Frameworks**: Embed enterprise values and industry-specific compliance into your AI lifecycle—from design to deployment.\n\n> **Bottom line**: In highly regulated industries like banking and healthcare, governance isn't just a best practice—it's a business requirement. The goal is to innovate *responsibly* and scale *safely*.\n\n---\n\n## Conclusion\n\nGenerative AI is more than a technological breakthrough — it represents a fundamental shift in how content is created and consumed. As organizations move beyond isolated experiments, the focus will shift toward embedding GenAI into real workflows, governed environments, and long-term value creation.\n\nLooking ahead, the next wave of GenAI will be defined by intelligent copilots, adaptive agents, and deeply integrated AI layers that understand industry context and human intent. This evolution will demand strong foundations in model governance, strategic use case alignment, and scalable architecture.","srcMarkdownNoYaml":"\n\n## Evolution of AI Capabilities\n\nAI has changed a lot over the past few decades. We've gone from simple rule-based systems to creative generative models, and now to AI that can plan and act on its own. Each stage brought new capabilities but also new challenges. To understand where we are today, it helps to look at these three types: Traditional AI, Generative AI, and Agentic AI.\n\n**AI paradigms**\n\n**Traditional AI** follows fixed rules and is great at repetitive tasks like sorting emails or detecting fraud. **Generative AI** can create new things—write text, generate images, or write code—by learning patterns from lots of data. **Agentic AI** goes even further: it can plan ahead, reason through problems, and handle multi-step tasks without much human help.\nHere's how they compare:\n\n\n<div style=\"overflow-x:auto;\">\n\n| Capability            | **Traditional AI**<br><small>Rule-driven tools</small> | **Generative AI**<br><small>Smart assistants</small> | **Agentic AI**<br><small>Autonomous actors</small> |\n|-----------------------|---------------------------------------------|--------------------------------------------|--------------------------------------------|\n| **What it does**      | Follows hard-coded logic and rules          | Understands prompts and generates output   | Plans, reasons, and acts across steps       |\n| **How it behaves**    | Rigid, predictable                          | Creative but guided                        | Goal-seeking and adaptive                   |\n| **Human involvement** | Fully manual setup and supervision          | Needs context and oversight                | Can operate independently (with guardrails) |\n| **Strengths**         | Reliable on structured tasks                | Great at summarizing, drafting, generating | Handles multistep workflows                 |\n| **Best used for**     | Repetitive decisions and automation         | Insight generation and copiloting          | Full process orchestration                  |\n\n</div>\n\nTraditional AI needs constant human direction. Generative AI acts more like a smart assistant. Agentic AI can work toward goals on its own, though it still needs guardrails. This evolution creates exciting opportunities, but it also raises important questions about safety and control.\n\nLet's explore why generative AI has become such a big deal.\n\n---\n\n## Why Generative AI Matters\n\nGenerative AI can create brand new content—text, images, code, you name it—by learning patterns from existing data. Unlike traditional AI that just sorts or labels things, generative models actually produce something new. Since 2022, this field has exploded. Models like ChatGPT, Claude, and Gemini are being used everywhere—from helping people write and create images to detecting fraud and generating synthetic data for testing.\n\n> **Business impact:** McKinsey estimates that generative AI could contribute up to **$4.4 trillion in annual global economic value**, with wide-ranging implications for productivity, personalization, and decision support.\n\nBut it's not all upside. GenAI can produce outputs that sound convincing but are completely wrong, biased, or even harmful. This is especially risky in fields like banking, healthcare, and law where mistakes have serious consequences. Making GenAI work responsibly means having strong governance, keeping humans in the loop, and deploying it ethically.\n\n---\n\n## How Generative Models Work\n\nNow that we've seen why GenAI matters, let's look under the hood. How do these models actually learn to create realistic content? The basic idea is pretty simple. These models look at tons of real examples—dog photos, text, whatever—and figure out the patterns. Then they use those patterns to make new stuff that looks real.\n\n![**Figure 1:** Generative models learn to approximate the true data distribution $P_{\\text{data}}$ by optimizing a parameterized model $P_\\theta$. The goal is to minimize divergence $d(P_{\\text{data}}, P_\\theta)$. *Source: Adapted from Stanford CS236.*](images/gen-ai.png)\n\nHere's what's going on under the hood:\n\nReal data has patterns. Dog photos usually have four legs, fur, a tail. We call this the data distribution $P_{\\text{data}}$. The model tries to learn this pattern by building its own version, called $P_\\theta$ (where $\\theta$ represents the model's internal settings).\n\nTraining means adjusting those settings until the model's distribution $P_\\theta$ matches the data distribution $P_{\\text{data}}$. The model keeps tweaking itself to minimize the gap between what it generates and what actually exists. Once trained, you can generate new content by sampling from what the model learned.\n\nThe basics:\n\n- The model learns a pattern $P_\\theta$ that captures what makes data look real\n- New content comes from sampling—drawing examples from this learned pattern\n- Training means making $P_\\theta$ match the real data pattern as closely as possible\n\n**Different models, different approaches:**\n\nDifferent types of models use different techniques to learn these patterns:\n\n- Autoregressive models (like GPT) and Normalizing Flows directly maximize how likely the real data is under their model\n- VAEs use a workaround called ELBO (Evidence Lower Bound) to approximate this\n- GANs pit two networks against each other—one creates fakes, the other spots them—until the fakes become incredibly convincing\n- Diffusion models and EBMs use techniques like score matching to learn the patterns\n\nThe key insight: all these models are trying to learn \"what real data looks like\" so they can create convincing new examples. They just take different paths to get there.\n\n---\n\n## How We Got Here\n\nTo understand today's AI, it helps to look back at the key breakthroughs that got us here. The timeline below shows how Generative AI evolved over five distinct periods:\n\n![**Figure:** Generative AI: Key Milestones. Tracks key advances from early neural nets and probabilistic models to modern transformers, diffusion models, and real-world deployment.](images/ai-timeline.png)\n\nEach era built on what came before, introducing new techniques and expanding what AI could do. Let's walk through each one.\n\n**1980–1990s: Early Foundations**\n\nIn the late 1980s, researchers introduced Recurrent Neural Networks (RNNs), which could process sequences of data like sentences or time series. LSTMs came in 1997, making it easier for models to remember context over longer sequences. Around the same time, early generative models started appearing—a shift from AI that just classified things to AI that could actually create new content. Probabilistic models like Bayesian networks and Hidden Markov Models gave us ways to model uncertainty and complex patterns. These weren't exciting, but they laid the groundwork for everything that followed.\n\n**2000s: Learning Better Representations**\n\nThe 2000s saw neural networks make a comeback. Researchers figured out how to train them to learn meaningful features from raw data automatically—no hand-crafted rules needed. The big breakthrough was Deep Belief Networks in 2006. They used a clever training trick called layer-wise pretraining that made deep learning practical again after years of disappointing results. This proved that neural networks could learn hierarchical patterns on their own, which opened the door to modern deep learning.\n\n**2010s: The Big Leap**\n\nThis decade brought the models that most people think of as \"modern AI.\" VAEs showed up in 2013 and GANs in 2014-both could generate realistic images and learn useful representations. Then came Transformers in 2017, which changed everything for language models. Their self-attention mechanism made it possible to build the large language models we use today. Diffusion models appeared in 2015 too, though they didn't work well until around 2020-2022. Together, these architectures created the foundation for the AI boom we're seeing now.\n\n**2020–2022: Going Big**\n\nGPT-3 launched in 2020 and DALL-E 2 in 2022, showing what massive models trained on huge datasets could do—write coherent essays, generate photorealistic images, you name it. Models got better at zero-shot and few-shot learning, meaning they could handle new tasks without needing specific training for each one. We also saw multimodal models that could work with text, images, and audio all at once. Diffusion models matured during this time too, often producing better images than GANs. This was when GenAI went from a research topic to something people could actually use.\n\n**2023–2025: Real-World Deployment**\n\nOpen-source models like LLaMA and Mistral made powerful AI accessible to more people, not just big tech companies with massive budgets. This competition sped up innovation. Tools like LangChain and RAG emerged to help AI systems do more complex, multi-step tasks and ground their outputs in real data. Companies started deploying GenAI in production, which meant they had to get serious about governance, safety, and making sure these systems were explainable and trustworthy. We're moving from \"cool demos\" to \"systems people rely on,\" which changes what matters.\n\nNow that we've seen how GenAI evolved, let's dive deeper into the main types of models. Each family has its own way of learning patterns and generating new content.\n\n---\n\n## Key Gen AI Model Families\n\nThese foundational architectures form the backbone of modern GenAI applications. Each family differs in how it models data distributions, handles sampling and inference, and supports various real-world use cases.\n\n### Variational Autoencoders (VAEs)\n- **Core Idea**: Encode input into a latent space and reconstruct while optimizing a lower bound on likelihood (ELBO).\n- **Likelihood**: Approximate (variational lower bound).\n- **Sampling**: Fast — sample latent vector and decode.\n- **Use Cases**: Representation learning, image generation.\n- **Example Models**: β-VAE, Conditional VAE  \n- [Go to VAE Models →](vae.qmd)\n\n### Autoregressive Models\n- **Core Idea**: Factor the joint distribution as a product of conditional probabilities.\n- **Likelihood**: Exact.\n- **Sampling**: Slow — token-by-token generation.\n- **Use Cases**: Language modeling, code generation, time series.\n- **Example Models**: GPT, PixelRNN  \n- [Go to Autoregressive Models →]\n\n### Normalizing Flows\n- **Core Idea**: Learn invertible transformations using the change-of-variable formula.\n- **Likelihood**: Exact and tractable.\n- **Sampling**: Fast — sample from base distribution and invert.\n- **Use Cases**: Density estimation, latent space modeling.\n- **Example Models**: RealNVP, Glow  \n- [Go to Flow Models →](flows.qmd)\n\n### Energy-Based Models (EBMs)\n- **Core Idea**: Define an energy function over inputs; lower energy = higher probability.\n- **Likelihood**: Unnormalized (intractable partition function).\n- **Sampling**: Very slow — requires MCMC or Langevin dynamics.\n- **Use Cases**: Uncertainty modeling, compositional generation.\n- **Example Models**: Score-based EBMs  \n- [Go to EBMs →](ebm.qmd)\n\n### Generative Adversarial Networks (GANs)\n- **Core Idea**: Generator and discriminator compete in a minimax game to produce realistic samples.\n- **Likelihood**: None (implicit model).\n- **Sampling**: Fast — sample latent vector and pass through generator.\n- **Use Cases**: High-quality image generation, style transfer.\n- **Example Models**: StyleGAN, CycleGAN  \n- [Go to GAN Models →]\n\n### Diffusion Models\n- **Core Idea**: Learn to reverse a gradual noise process via denoising.\n- **Likelihood**: Approximate (via variational bound).\n- **Sampling**: Slow — requires hundreds of reverse steps.\n- **Use Cases**: High-resolution image and audio generation.\n- **Example Models**: Stable Diffusion  \n- [Go to Diffusion Models →](diffusion.qmd)\n\n\n::: {.callout-tip title=\"Explore Related Topics\"}\nExpand your understanding of Generative AI with these supporting deep dives:\n\n- [Transformers →](transformers.qmd)  \n  Understand the self-attention architecture behind modern LLMs and Gen AI models.\n\n- [Post-Training Techniques →](post-training.qmd)  \n  Learn how fine-tuning, RLHF, and instruction tuning make base models usable in the real world.\n\n- [Evaluation Strategies →](nlp-eval.qmd)  \n  Discover how we evaluate GenAI output quality — from traditional metrics to modern LLM-based approaches.\n:::\n\n---\n\n## Use-Case Framing & Prioritization\n\nBefore diving into specific industry use cases, it's critical to assess *where* and *how* generative AI can deliver real value. Not every idea is equally feasible, impactful, or low-risk. A structured framing process helps ensure that AI initiatives align with business priorities and responsible innovation.\n\nWe recommend evaluating GenAI use cases across three key dimensions:\n\n- **Business Value**: Consider how the use case impacts revenue generation, cost reduction, operational efficiency, risk mitigation, or customer experience. This ensures alignment with strategic business outcomes.\n\n- **Feasibility**: Evaluate the availability and quality of data, the readiness of models, the complexity of integration, and infrastructure or compute requirements. This grounds ideas in technical and operational reality.\n\n- **Governance Sensitivity**: Assess how much oversight is needed to meet regulatory, ethical, or reputational expectations—especially in domains like banking and healthcare. This includes explainability, auditability, and the potential for misuse.\n\nThis framing helps prioritize AI use cases that are not only **promising**, but also **implementable** and **sustainable**—especially in highly regulated environments.\n\n---\n\n## Industry Use Cases\n\nGenAI is being deployed across industries in two ways: **horizontal use cases** that work everywhere, and **industry-specific applications** tailored to particular sectors. Let's look at both.\n\n### Horizontal Use Cases (Apply Across Industries)\n\nThese use cases work in nearly any industry—they're about common business functions like content creation, customer service, and compliance.\n\n| **Use Case**             | **What It Does**                                                                 | **Business Impact**                                                                |\n|--------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|\n| **Content Generation**   | Creates reports, emails, social media posts                              | Scale content marketing efforts without proportional headcount increases           |\n| **Personalized Marketing** | Generates customized emails, landing pages, and social posts                  | Reach target audiences more effectively and increase conversion rates              |\n| **Customer Service**     | Powers chatbots that answer questions and resolve problems                       | Free up human agents to focus on complex issues                                    |\n| **Risk Management**      | Identifies and predicts fraud, cyberattacks, supply chain disruptions            | Mitigate risks and protect assets before problems occur                            |\n| **Compliance**           | Generates compliant documents like contracts, reports, disclosures               | Save time and money while reducing noncompliance risk                              |\n| **Software Development** | Generates code, provides snippets, documents and refactors code                  | Speed up development, reduce errors, generate test cases                           |\n| **Data Augmentation**    | Creates synthetic data when real data is insufficient                            | Enable model training when privacy or scarcity limits real data availability       |\n| **Contract Management**  | Drafts legal documents and understands regulatory requirements                   | Reduce human mistakes and make informed decisions faster                           |\n\n\n### Banking & Financial Services\n\nFinancial institutions use GenAI for scenario modeling, risk assessment, and customer operations—all while navigating strict regulatory requirements.\n\n| **Use Case**                   | **Example Application**                                                                 |\n|--------------------------------|------------------------------------------------------------------------------------------|\n| **Customer Service**           | Virtual agents for handling account queries and FAQs                                     |\n| **Fraud Detection**            | Real-time anomaly detection in transaction behavior                                      |\n| **Risk Modeling**              | Scenario analysis for credit risk and market stress testing                              |\n| **Operational Efficiency**     | Auto-summarizing calls and processing back-office documents                              |\n| **Business Intelligence**      | Spotting unusual patterns in product or branch-level KPIs                                |\n| **Marketing & Personalization**| Creating personalized offers based on customer behavior and transaction history          |\n| **Product Development**        | Simulating scenarios to develop new financial products and services                      |\n\n**What makes financial services different:**  \nDecision-making requires scenario simulation, risk model assessment, and customer personalization based on transaction history. Everything must be explainable and auditable for regulators.\n\n> Real-world examples from JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley.  \n> **[View complete banking implementation guide →](gen-ai-use-cases/banking-use-cases.html)**\n\n---\n\n### Healthcare & Life Sciences\n\nHealthcare organizations deploy GenAI for drug discovery, clinical documentation, and personalized treatment—all while maintaining patient privacy and safety standards.\n\n| **Use Case**              | **Example Application**                                                                      |\n|---------------------------|-----------------------------------------------------------------------------------------------|\n| **Clinical Documentation**| Auto-generating visit summaries and physician notes                                           |\n| **Drug Discovery**        | Accelerating compound generation and molecular simulation                                     |\n| **Medical Device Design** | Creating and optimizing new medical devices                                                   |\n| **Treatment Plans**       | Generating personalized patient treatment plans                                               |\n| **Medical Imaging**       | Improving and reconstructing radiological images                                              |\n| **Diagnostics & Triage**  | Supporting diagnosis with uncertainty-aware modeling (confidence scores)                      |\n| **Patient Education**     | Explaining test results, medication instructions, and drug interactions in plain language     |\n\n**What makes healthcare different:**  \nGenAI develops new drugs and treatments, designs medical devices, creates personalized treatment plans, and generates patient documentation on instructions, risks, and drug interactions. Patient safety and privacy (HIPAA) are non-negotiable.\n\n> Examples from Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine.  \n> **[View complete healthcare implementation guide →](gen-ai-use-cases/healthcare-use-cases.html)**\n\n---\n\n## Governance & Risk Warnings\n\nGenerative AI introduces exciting new capabilities—but also carries **unique risks** that traditional analytics and rules-based systems did not. Without strong governance, these risks can quickly undermine trust, compliance, and effectiveness.\n\n**Key Risks to Watch:**\n\n- **Inaccuracy & Hallucination**: GenAI can confidently generate responses that sound right—but are completely wrong or misleading.\n- **Bias & Fairness**: Models can unintentionally reinforce historical bias found in training data. These outcomes could affect customers or patients.\n- **Security & Privacy**: Prompts or training data may inadvertently expose sensitive, private, or proprietary information.\n- **Overtrust**: Users may take outputs at face value without critical thinking, especially in high-volume environments like BI dashboards or chatbots.\n- **Regulatory Exposure**: Lack of transparency, explainability, or auditability may put the organization at odds with standards such as OCC guidelines, HIPAA, GDPR, or emerging AI laws.\n\n**Governance Practices to Put in Place:**\n\n- **Human-in-the-Loop (HITL)**: Require review and validation for GenAI-generated content in regulated or customer-facing contexts.\n- **Explainability & Traceability**: Where possible, use interpretable model frameworks, or add metadata like model version, confidence score, or decision path.\n- **Prompt & Output Logging**: Maintain logs of GenAI usage for auditing, debugging, and continuous refinement.\n- **Access Control & Masking**: Limit who can access GenAI systems and ensure sensitive data is redacted before prompt injection or model training.\n- **Alignment with Ethical and Regulatory Frameworks**: Embed enterprise values and industry-specific compliance into your AI lifecycle—from design to deployment.\n\n> **Bottom line**: In highly regulated industries like banking and healthcare, governance isn't just a best practice—it's a business requirement. The goal is to innovate *responsibly* and scale *safely*.\n\n---\n\n## Conclusion\n\nGenerative AI is more than a technological breakthrough — it represents a fundamental shift in how content is created and consumed. As organizations move beyond isolated experiments, the focus will shift toward embedding GenAI into real workflows, governed environments, and long-term value creation.\n\nLooking ahead, the next wave of GenAI will be defined by intelligent copilots, adaptive agents, and deeply integrated AI layers that understand industry context and human intent. This evolution will demand strong foundations in model governance, strategic use case alignment, and scalable architecture."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"number-sections":true,"html-math-method":"mathjax","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","resources":["images/**"],"theme":"cosmo","title":"Deep Generative Models"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}