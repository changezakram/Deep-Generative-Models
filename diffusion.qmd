---
title: "Diffusion Models"  
---

## Introduction 

Diffusion models are a class of generative models that create data (like images) by reversing a gradual noising process. First, they take real data and add random noise to it step by step, until it becomes pure noise. Then, they train a neural network to undo this process, transforming noise back into realistic data. This method has enabled state-of-the-art results in image generation, powering tools like DALL-E 2 and Stable Diffusion. Unlike older methods, diffusion models are stable to train and can produce highly detailed, diverse outputs.

## Math Review

### Forward Diffusion Process

The forward diffusion process gradually turns a data sample (such as an image) into pure noise by adding a little bit of random noise at each step. This process is a Markov chain, meaning each step depends only on the previous one.

#### Start with a Data Sample

Begin with a data point $x_0$, sampled from dataset (such as a real image). The goal is to slowly corrupt $x_0$ by adding noise over many steps, until it becomes pure noise.  
We’ll later see that it’s also possible to sample $x_t$ directly from $x_0$, without simulating every step.

#### Add Noise Recursively

At each time step $t$, the process is defined as:
$$
q(x_t \mid x_{t-1}) = \mathcal{N}\left(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) I\right)
$$

Where:

- $\alpha_t = 1 - \beta_t$, with $\beta_t$ a small positive number controlling the noise level at step $t$  
- $I$ is the identity matrix, so noise is added independently to each component.

::: {.callout-note appearance="simple"}
**Intuition:** Each step shrinks the previous value a bit and adds some Gaussian noise. As the process repeats, the sample becomes more and more like random noise.
:::

#### The Markov Chain

The full sequence is:

$$
x_0 \rightarrow x_1 \rightarrow x_2 \rightarrow \ldots \rightarrow x_T
$$

The joint probability of the sequence is:

$$
q(x_{1:T} \mid x_0) = \prod_{t=1}^{T} q(x_t \mid x_{t-1})
$$

This means we can sample the whole chain by repeatedly applying the noise step.

::: {.callout-note appearance="simple"}
**Insight:** While the forward process defines a full Markov chain from $x_0$ to $x_T$, we’ll soon see that it’s also possible to sample any $x_t$ directly from $x_0$ using a closed-form Gaussian — without simulating each intermediate step.
:::

#### Deriving the Marginal Distribution $q(x_t \mid x_0)$

\textbf{Key Question:} How do we get the formula that lets us sample $x_t$ directly from $x_0$ (without simulating all the intermediate steps)?

\textbf{a. Unrolling the Recursion}

Let’s see how $x_t$ is built up from $x_0$:

For $t = 1$:
$$
x_1 = \sqrt{\alpha_1} x_0 + \sqrt{1 - \alpha_1} \epsilon_1, \qquad \epsilon_1 \sim \mathcal{N}(0, I)
$$

For $t = 2$:
$$
x_2 = \sqrt{\alpha_2} x_1 + \sqrt{1 - \alpha_2} \epsilon_2
$$
Substitute $x_1$:
$$
x_2 = \sqrt{\alpha_2} \left( \sqrt{\alpha_1} x_0 + \sqrt{1 - \alpha_1} \epsilon_1 \right) + \sqrt{1 - \alpha_2} \epsilon_2
$$
$$
= \sqrt{\alpha_2 \alpha_1} x_0 + \sqrt{\alpha_2 (1 - \alpha_1)} \epsilon_1 + \sqrt{1 - \alpha_2} \epsilon_2
$$

For general $t$, recursively expanding gives:
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sum_{i=1}^t \left( \sqrt{ \left( \prod_{j=i+1}^t \alpha_j \right) (1 - \alpha_i) } \, \epsilon_i \right)
$$
where $\bar{\alpha}_t = \prod_{i=1}^t \alpha_i$.

Each $\epsilon_i$ is independent Gaussian noise. The sum of independent Gaussians (each scaled by a constant) is still a Gaussian, with variance equal to the sum of the variances:
$$
\text{Total variance} = \sum_{i=1}^t \left( \prod_{j=i+1}^t \alpha_j \right) (1 - \alpha_i)
$$
This sum simplifies to:
$$
1 - \bar{\alpha}_t
$$

This can be proved by induction or by telescoping the sum.

All the little bits of noise added at each step combine into one big Gaussian noise term, with variance $1 - \bar{\alpha}_t$.

#### The Final Marginal Distribution

So, we can sample $x_t$ directly from $x_0$ using:
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \qquad \epsilon \sim \mathcal{N}(0, I)
$$

This lets us sample $x_t$ directly from $x_0$, without recursively computing all previous steps $x_1, x_2, \dots, x_{t-1}$.

This means:
$$
q(x_t \mid x_0) = \mathcal{N}\left(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I\right)
$$

After $t$ steps, sample is a faded version of the original plus one big chunk of noise.

#### What Happens as $t$ Gets Large?

As $t$ increases, $\bar{\alpha}_t$ shrinks toward zero. Eventually, $x_t$ becomes pure noise:
$$
x_T \sim \mathcal{N}(0, I)
$$

#### Recap: Forward Diffusion Steps

| **Step** | **Formula** | **Explanation** |
|---------|-------------|-----------------|
| 1 | $x_0$ | Original data sample |
| 2 | $q(x_t \mid x_{t-1}) = \mathcal{N}(\sqrt{\alpha_t} x_{t-1}, (1-\alpha_t) I)$ | Add noise at each step |
| 3 | $x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon$ | Directly sample $x_t$ from $x_0$ using noise $\epsilon$ |
| 4 | $q(x_t \mid x_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) I)$ | Marginal distribution at step $t$ |
| 5 | $x_T \sim \mathcal{N}(0, I)$ | After many steps, pure noise |


#### Key Takeaways

- The forward diffusion process is just repeatedly adding noise to your data.
- Thanks to properties of Gaussian noise, you can describe the result as the original data scaled down plus one cumulative chunk of Gaussian noise.   
- After enough steps, the data becomes indistinguishable from random noise.







## Reverse Diffusion Process

Let’s break down the reverse diffusion process step by step. This is the **generative phase** of diffusion models, where we learn to turn pure noise back into data. For clarity, we’ll use the same notation as in the forward process:

- **Forward process**: Gradually adds noise to data via $q(x_t \mid x_{t-1})$
- **Reverse process**: Gradually removes noise via $p_\theta(x_{t-1} \mid x_t)$, learned by a neural network

---

### The Goal of the Reverse Process

**Objective**: Given a noisy sample $x_t$, we want to estimate the conditional distribution $q(x_{t-1} \mid x_t)$. However, this is **intractable** because it would require knowing the true data distribution.

Instead, we train a neural network to approximate it:
$$
p_\theta(x_{t-1} \mid x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$

---

### Key Insight from the Forward Process

If the noise added in the forward process is small (i.e., $\beta_t \ll 1$), then the reverse conditional $q(x_{t-1} \mid x_t)$ is also Gaussian:
$$
q(x_{t-1} \mid x_t) \approx \mathcal{N}(x_{t-1}; \tilde{\mu}_t(x_t), \tilde{\beta}_t I)
$$

---

### Deriving \( q(x_{t-1} \mid x_t, x_0) \) Using Bayes’ Rule

We can't directly evaluate $q(x_{t-1} \mid x_t)$, but we can derive the **posterior** $q(x_{t-1} \mid x_t, x_0)$:

From the forward process, we know:

- $q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) I)$  
- $q(x_{t-1} \mid x_0) = \mathcal{N}(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}} x_0, (1 - \bar{\alpha}_{t-1}) I)$  
- $q(x_t \mid x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)$

Substituting into Bayes’ rule:
$$
q(x_{t-1} \mid x_t, x_0) = \mathcal{N}(x_{t-1}; \tilde{\mu}_t(x_t, x_0), \tilde{\beta}_t I)
$$

---

### Completing the Square for the Gaussian

We simplify the exponent into a quadratic form and combine terms. This gives us:
$$
\tilde{\mu}_t(x_t, x_0) = 
\frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} x_0 + 
\frac{\sqrt{\alpha_t} (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t
$$

$$
\tilde{\beta}_t = \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t}
$$

---

### Parameterizing the Reverse Process

During sampling, we **don't know** $x_0$, so we use the forward reparameterization:
$$
x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon
\quad \Rightarrow \quad
x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} \left(x_t - \sqrt{1 - \bar{\alpha}_t} \, \epsilon \right)
$$

Substituting this into $\tilde{\mu}_t$ gives us a version based only on $x_t$ and the noise $\epsilon$, which can be predicted by a neural network.

---

### Training the Neural Network

The reverse process is implemented as a neural network (often a U-Net), which is trained to **predict the noise** $\epsilon$ from $x_t$ at each step. The forward process is fixed and non-learned.

Let $\epsilon_\theta(x_t, t)$ be the network's prediction. Then the training objective is:
$$
\mathcal{L}_{\text{simple}} = \mathbb{E}_{t, x_0, \epsilon \sim \mathcal{N}(0, I)} 
\left[ \left\| \epsilon - \epsilon_\theta(x_t, t) \right\|^2 \right]
$$

::: {.callout-note appearance="simple"}
**Intuition:** The model learns to "denoise" each $x_t$ by predicting the noise that was added to create it.
:::

---

### Sampling (Generating New Data)

To generate a sample:

1. Sample noise: $x_T \sim \mathcal{N}(0, I)$  
2. For each $t = T, T-1, ..., 1$:
   - Predict noise: $\epsilon_\theta(x_t, t)$
   - Compute $x_{t-1}$ as:
$$
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left(x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t)\right) + \sigma_t z
$$
Where:
- $z \sim \mathcal{N}(0, I)$  
- $\sigma_t^2 = \beta_t$

---

### Simplifications in DDPM

In the **Denoising Diffusion Probabilistic Models (DDPM)** paper:

- The variance is fixed: $\Sigma_\theta = \beta_t I$
- The stochastic term $z$ is removed for **deterministic** sampling

This simplifies the sampling equation to:
$$
x_{t-1} = \mu_\theta(x_t, t)
$$

---

### In Summary

- The forward process is a fixed schedule of adding Gaussian noise.
- The reverse process is **learned** by a neural network that predicts noise $\epsilon$ at each step.
- Sampling starts from pure noise and applies the learned denoising steps iteratively.