---
title: "Deep Generative Models"
---

## Evolution of AI Capabilities

AI has changed a lot over the past few decades. We've gone from simple rule-based systems to creative generative models, and now to AI that can plan and act on its own. Each stage brought new capabilities but also new challenges. To understand where we are today, it helps to look at these three types: Traditional AI, Generative AI, and Agentic AI.

**Traditional AI** follows fixed rules and is great at repetitive tasks like sorting emails or detecting fraud. **Generative AI** can create new things—write text, generate images, or write code—by learning patterns from lots of data. **Agentic AI** goes even further: it can plan ahead, reason through problems, and handle multi-step tasks without much human help.
Here's how they compare:


<div style="overflow-x:auto;">

| Capability            | **Traditional AI**<br><small>Rule-driven tools</small> | **Generative AI**<br><small>Smart assistants</small> | **Agentic AI**<br><small>Autonomous actors</small> |
|-----------------------|---------------------------------------------|--------------------------------------------|--------------------------------------------|
| **What it does**      | Follows hard-coded logic and rules          | Understands prompts and generates output   | Plans, reasons, and acts across steps       |
| **How it behaves**    | Rigid, predictable                          | Creative but guided                        | Goal-seeking and adaptive                   |
| **Human involvement** | Fully manual setup and supervision          | Needs context and oversight                | Can operate independently (with guardrails) |
| **Strengths**         | Reliable on structured tasks                | Great at summarizing, drafting, generating | Handles multistep workflows                 |
| **Best used for**     | Repetitive decisions and automation         | Insight generation and copiloting          | Full process orchestration                  |

</div>

Traditional AI needs constant human direction. Generative AI acts more like a smart assistant. Agentic AI can work toward goals on its own, though it still needs guardrails. This evolution creates exciting opportunities, but it also raises important questions about safety and control.

Let's explore why generative AI has become such a big deal.

---

## Why Generative AI Matters

Generative AI can create brand new content—text, images, code, you name it—by learning patterns from existing data. Unlike traditional AI that just sorts or labels things, generative models actually produce something new. Since 2022, this field has exploded. Models like ChatGPT, Claude, and Gemini are being used everywhere—from helping people write and create images to detecting fraud and generating synthetic data for testing.

> **Business impact:** McKinsey estimates that generative AI could contribute up to **$4.4 trillion in annual global economic value**, with wide-ranging implications for productivity, personalization, and decision support.

But it's not all upside. GenAI can produce outputs that sound convincing but are completely wrong, biased, or even harmful. This is especially risky in fields like banking, healthcare, and law where mistakes have serious consequences. Making GenAI work responsibly means having strong governance, keeping humans in the loop, and deploying it ethically.

---

## How Generative Models Work

Now that we've seen why GenAI matters, let's look under the hood. How do these models actually learn to create realistic content? The basic idea is pretty simple. These models look at tons of real examples—dog photos, text, whatever—and figure out the patterns. Then they use those patterns to make new stuff that looks real.

![**Figure 1:** Generative models learn to approximate the true data distribution $P_{\text{data}}$ by optimizing a parameterized model $P_\theta$. The goal is to minimize divergence $d(P_{\text{data}}, P_\theta)$. *Source: Adapted from Stanford CS236.*](images/gen-ai.png)

Here's what's going on under the hood:

Real data has patterns. Dog photos usually have four legs, fur, a tail. We call this the data distribution $P_{\text{data}}$. The model tries to learn this pattern by building its own version, called $P_\theta$ (where $\theta$ represents the model's internal settings).

Training means adjusting those settings until the model's distribution $P_\theta$ matches the data distribution $P_{\text{data}}$. The model keeps tweaking itself to minimize the gap between what it generates and what actually exists. Once trained, you can generate new content by sampling from what the model learned.

The basics:

- The model learns a pattern $P_\theta$ that captures what makes data look real
- New content comes from sampling—drawing examples from this learned pattern
- Training means making $P_\theta$ match the real data pattern as closely as possible

**Different models, different approaches:**

Different types of models use different techniques to learn these patterns:

- Autoregressive models (like GPT) and Normalizing Flows directly maximize how likely the real data is under their model
- VAEs use a workaround called ELBO (Evidence Lower Bound) to approximate this
- GANs pit two networks against each other—one creates fakes, the other spots them—until the fakes become incredibly convincing
- Diffusion models and EBMs use techniques like score matching to learn the patterns

The key insight: all these models are trying to learn "what real data looks like" so they can create convincing new examples. They just take different paths to get there.

---

## How We Got Here

To understand today's AI, it helps to look back at the key breakthroughs that got us here. The timeline below shows how Generative AI evolved over five distinct periods:

![**Figure:** Generative AI: Key Milestones. Tracks key advances from early neural nets and probabilistic models to modern transformers, diffusion models, and real-world deployment.](images/ai-timeline.png)

Each era built on what came before, introducing new techniques and expanding what AI could do. Let's walk through each one.

**1980–1990s: Early Foundations**

In the late 1980s, researchers introduced Recurrent Neural Networks (RNNs), which could process sequences of data like sentences or time series. LSTMs came in 1997, making it easier for models to remember context over longer sequences. Around the same time, early generative models started appearing—a shift from AI that just classified things to AI that could actually create new content. Probabilistic models like Bayesian networks and Hidden Markov Models gave us ways to model uncertainty and complex patterns. These weren't exciting, but they laid the groundwork for everything that followed.

**2000s: Learning Better Representations**

The 2000s saw neural networks make a comeback. Researchers figured out how to train them to learn meaningful features from raw data automatically—no hand-crafted rules needed. The big breakthrough was Deep Belief Networks in 2006. They used a clever training trick called layer-wise pretraining that made deep learning practical again after years of disappointing results. This proved that neural networks could learn hierarchical patterns on their own, which opened the door to modern deep learning.

**2010s: The Big Leap**

This decade brought the models that most people think of as "modern AI." VAEs showed up in 2013 and GANs in 2014-both could generate realistic images and learn useful representations. Then came Transformers in 2017, which changed everything for language models. Their self-attention mechanism made it possible to build the large language models we use today. Diffusion models appeared in 2015 too, though they didn't work well until around 2020-2022. Together, these architectures created the foundation for the AI boom we're seeing now.

**2020–2022: Going Big**

GPT-3 launched in 2020 and DALL-E 2 in 2022, showing what massive models trained on huge datasets could do—write coherent essays, generate photorealistic images, you name it. Models got better at zero-shot and few-shot learning, meaning they could handle new tasks without needing specific training for each one. We also saw multimodal models that could work with text, images, and audio all at once. Diffusion models matured during this time too, often producing better images than GANs. This was when GenAI went from a research topic to something people could actually use.

**2023–2025: Real-World Deployment**

Open-source models like LLaMA and Mistral made powerful AI accessible to more people, not just big tech companies with massive budgets. This competition sped up innovation. Tools like LangChain and RAG emerged to help AI systems do more complex, multi-step tasks and ground their outputs in real data. Companies started deploying GenAI in production, which meant they had to get serious about governance, safety, and making sure these systems were explainable and trustworthy. We're moving from "cool demos" to "systems people rely on," which changes what matters.

Now that we've seen how GenAI evolved, let's dive deeper into the main types of models. Each family has its own way of learning patterns and generating new content.

---

## Key Gen AI Model Families

Now that we've seen how GenAI evolved, let's look at the main types of models powering today's applications. Each family takes a different approach to learning and generating content.


### Variational Autoencoders (VAEs)

VAEs compress data into a compact representation (the "latent space"), then reconstruct it. They use a technique called ELBO (Evidence Lower Bound) to approximate the data distribution efficiently.**Examples:** β-VAE, Conditional VAE. 
[Learn more about VAE Models →](vae.qmd)

### Autoregressive Models

These models generate content one piece at a time, like writing a sentence word by word. Each new piece depends on everything that came before it. GPT works this way—it predicts the next token based on all previous tokens.
**Examples:** GPT, PixelRNN

### Normalizing Flows

Normalizing Flows transform simple random noise into complex data through a series of reversible steps. Because everything is reversible, they can compute exact probabilities.
**Examples:** RealNVP, Glow. [Learn more about Flow Models →](flows.qmd)

### Energy-Based Models (EBMs)

EBMs assign an "energy level" to every possible input—real data gets low energy, fake data gets high energy. The model learns what energy patterns correspond to real data.
**Examples:** Score-based EBMs. [Learn more about EBMs →](ebm.qmd)

### Generative Adversarial Networks (GANs)

GANs pit two networks against each other: one creates fakes (generator), the other tries to spot them (discriminator). They compete until the fakes become convincing enough to fool the discriminator.
**Examples:** StyleGAN, CycleGAN

### Diffusion Models

Diffusion models start with pure noise and gradually remove it step by step to reveal a clean image. The model learns how to denoise at each step, working backwards from random noise to realistic data.
**Examples:** Stable Diffusion. [Learn more about Diffusion Models →](diffusion.qmd)


::: {.callout-tip title="Explore Related Topics"}
Expand your understanding of Generative AI with these supporting deep dives:

- [Transformers →](transformers.qmd)  
  Understand the self-attention architecture behind modern LLMs and Gen AI models.

- [Post-Training Techniques →](post-training.qmd)  
  Learn how fine-tuning, RLHF, and instruction tuning make base models usable in the real world.

- [Evaluation Strategies →](nlp-eval.qmd)  
  Discover how we evaluate GenAI output quality — from traditional metrics to modern LLM-based approaches.
:::

---

## Use-Case Framing & Prioritization

Before diving into specific industry use cases, it's critical to assess *where* and *how* generative AI can deliver real value. Not every idea is equally feasible, impactful, or low-risk. A structured framing process helps ensure that AI initiatives align with business priorities and responsible innovation.

We recommend evaluating GenAI use cases across three key dimensions:

- **Business Value**: Consider how the use case impacts revenue generation, cost reduction, operational efficiency, risk mitigation, or customer experience. This ensures alignment with strategic business outcomes.

- **Feasibility**: Evaluate the availability and quality of data, the readiness of models, the complexity of integration, and infrastructure or compute requirements. This grounds ideas in technical and operational reality.

- **Governance Sensitivity**: Assess how much oversight is needed to meet regulatory, ethical, or reputational expectations—especially in domains like banking and healthcare. This includes explainability, auditability, and the potential for misuse.

This framing helps prioritize AI use cases that are not only **promising**, but also **implementable** and **sustainable**—especially in highly regulated environments.

---

## Industry Use Cases

GenAI is being deployed across industries in two ways: **horizontal use cases** that work everywhere, and **industry-specific applications** tailored to particular sectors. Let's look at both.

### Horizontal Use Cases (Apply Across Industries)

These use cases work in nearly any industry—they're about common business functions like content creation, customer service, and compliance.

| **Use Case**             | **What It Does**                                                                 | **Business Impact**                                                                |
|--------------------------|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|
| **Content Generation**   | Creates reports, emails, social media posts                              | Scale content marketing efforts without proportional headcount increases           |
| **Personalized Marketing** | Generates customized emails, landing pages, and social posts                  | Reach target audiences more effectively and increase conversion rates              |
| **Customer Service**     | Powers chatbots that answer questions and resolve problems                       | Free up human agents to focus on complex issues                                    |
| **Risk Management**      | Identifies and predicts fraud, cyberattacks, supply chain disruptions            | Mitigate risks and protect assets before problems occur                            |
| **Compliance**           | Generates compliant documents like contracts, reports, disclosures               | Save time and money while reducing noncompliance risk                              |
| **Software Development** | Generates code, provides snippets, documents and refactors code                  | Speed up development, reduce errors, generate test cases                           |
| **Data Augmentation**    | Creates synthetic data when real data is insufficient                            | Enable model training when privacy or scarcity limits real data availability       |
| **Contract Management**  | Drafts legal documents and understands regulatory requirements                   | Reduce human mistakes and make informed decisions faster                           |


### Banking & Financial Services

Financial institutions use GenAI for scenario modeling, risk assessment, and customer operations—all while navigating strict regulatory requirements.

| **Use Case**                   | **Example Application**                                                                 |
|--------------------------------|------------------------------------------------------------------------------------------|
| **Customer Service**           | Virtual agents for handling account queries and FAQs                                     |
| **Fraud Detection**            | Real-time anomaly detection in transaction behavior                                      |
| **Risk Modeling**              | Scenario analysis for credit risk and market stress testing                              |
| **Operational Efficiency**     | Auto-summarizing calls and processing back-office documents                              |
| **Business Intelligence**      | Spotting unusual patterns in product or branch-level KPIs                                |
| **Marketing & Personalization**| Creating personalized offers based on customer behavior and transaction history          |
| **Product Development**        | Simulating scenarios to develop new financial products and services                      |

**What makes financial services different:**  
Decision-making requires scenario simulation, risk model assessment, and customer personalization based on transaction history. Everything must be explainable and auditable for regulators.

> Real-world examples from JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley.  
> **[View complete banking implementation guide →](gen-ai-use-cases/banking-use-cases.html)**

---

### Healthcare & Life Sciences

Healthcare organizations deploy GenAI for drug discovery, clinical documentation, and personalized treatment—all while maintaining patient privacy and safety standards.

| **Use Case**              | **Example Application**                                                                      |
|---------------------------|-----------------------------------------------------------------------------------------------|
| **Clinical Documentation**| Auto-generating visit summaries and physician notes                                           |
| **Drug Discovery**        | Accelerating compound generation and molecular simulation                                     |
| **Medical Device Design** | Creating and optimizing new medical devices                                                   |
| **Treatment Plans**       | Generating personalized patient treatment plans                                               |
| **Medical Imaging**       | Improving and reconstructing radiological images                                              |
| **Diagnostics & Triage**  | Supporting diagnosis with uncertainty-aware modeling (confidence scores)                      |
| **Patient Education**     | Explaining test results, medication instructions, and drug interactions in plain language     |

**What makes healthcare different:**  
GenAI develops new drugs and treatments, designs medical devices, creates personalized treatment plans, and generates patient documentation on instructions, risks, and drug interactions. Patient safety and privacy (HIPAA) are non-negotiable.

> Examples from Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine.  
> **[View complete healthcare implementation guide →](gen-ai-use-cases/healthcare-use-cases.html)**

---

## Governance & Risk Warnings

Generative AI introduces exciting new capabilities—but also carries **unique risks** that traditional analytics and rules-based systems did not. Without strong governance, these risks can quickly undermine trust, compliance, and effectiveness.

**Key Risks to Watch:**

- **Inaccuracy & Hallucination**: GenAI can confidently generate responses that sound right—but are completely wrong or misleading.
- **Bias & Fairness**: Models can unintentionally reinforce historical bias found in training data. These outcomes could affect customers or patients.
- **Security & Privacy**: Prompts or training data may inadvertently expose sensitive, private, or proprietary information.
- **Overtrust**: Users may take outputs at face value without critical thinking, especially in high-volume environments like BI dashboards or chatbots.
- **Regulatory Exposure**: Lack of transparency, explainability, or auditability may put the organization at odds with standards such as OCC guidelines, HIPAA, GDPR, or emerging AI laws.

**Governance Practices to Put in Place:**

- **Human-in-the-Loop (HITL)**: Require review and validation for GenAI-generated content in regulated or customer-facing contexts.
- **Explainability & Traceability**: Where possible, use interpretable model frameworks, or add metadata like model version, confidence score, or decision path.
- **Prompt & Output Logging**: Maintain logs of GenAI usage for auditing, debugging, and continuous refinement.
- **Access Control & Masking**: Limit who can access GenAI systems and ensure sensitive data is redacted before prompt injection or model training.
- **Alignment with Ethical and Regulatory Frameworks**: Embed enterprise values and industry-specific compliance into your AI lifecycle—from design to deployment.

> **Bottom line**: In highly regulated industries like banking and healthcare, governance isn't just a best practice—it's a business requirement. The goal is to innovate *responsibly* and scale *safely*.

---

## Conclusion

Generative AI is more than a technological breakthrough — it represents a fundamental shift in how content is created and consumed. As organizations move beyond isolated experiments, the focus will shift toward embedding GenAI into real workflows, governed environments, and long-term value creation.

Looking ahead, the next wave of GenAI will be defined by intelligent copilots, adaptive agents, and deeply integrated AI layers that understand industry context and human intent. This evolution will demand strong foundations in model governance, strategic use case alignment, and scalable architecture.