---
title: "Deep Generative Models"
---

## Overview

Generative machine learning models aim to learn the underlying distribution of real-world data, typically denoted as $p_{\text{data}}(x)$. Their goal is to approximate this distribution as closely as possible.


- The distribution learned by the model is denoted as $p_\theta(x)$  
- We generate new data by **sampling** from this learned distribution  
- In practice, generative models are trained to **maximize the expected log-likelihood** of $p_\theta(x)$, or equivalently, **minimize the divergence** between $p_\theta(x)$ and $p_{\text{data}}(x)$

This site explores how different model families approach this goal — from Variational Autoencoders (VAEs) to Diffusion Models — grounded in theory and real-world use.

## Key Model Families

<details>
<summary><strong> Variational Autoencoders (VAEs)</strong></summary>

- **Core Idea**: Encode input to a latent space and reconstruct it while optimizing a lower bound on likelihood (ELBO).
- **Likelihood**: Approximate (variational lower bound).
- **Sampling**: Fast — sample latent vector and decode.
- **Use Cases**: Representation learning, image generation.
- **Example Models**: β-VAE, Conditional VAE
- [Go to VAE write-up →](vae.qmd)

</details>

<details>
<summary><strong> Generative Adversarial Networks (GANs)</strong></summary>

- **Core Idea**: A generator and discriminator compete in a minimax game to produce realistic samples.
- **Likelihood**: None (implicit model).
- **Sampling**: Fast — sample latent vector and pass through generator.
- **Use Cases**: High-quality image generation, style transfer.
- **Example Models**: StyleGAN, CycleGAN
- [Go to GAN write-up →]

</details>

<details>
<summary><strong> Autoregressive Models</strong></summary>

- **Core Idea**: Factor the joint distribution as a product of conditional probabilities.
- **Likelihood**: Exact.
- **Sampling**: Slow — token-by-token generation.
- **Use Cases**: Language modeling, code generation, time series.
- **Example Models**: GPT, PixelRNN
- [Go to Autoregressive Models →]

</details>

<details>
<summary><strong> Normalizing Flows</strong></summary>

- **Core Idea**: Learn invertible transformations of latent variables using the change-of-variable formula.
- **Likelihood**: Exact and tractable.
- **Sampling**: Fast — sample from base distribution and invert.
- **Use Cases**: Density estimation, latent space modeling.
- **Example Models**: RealNVP, Glow
- [Go to Flow Models →](flows.qmd)

</details>

<details>
<summary><strong> Energy-Based Models (EBMs)</strong></summary>

- **Core Idea**: Define an energy function over inputs; lower energy = higher probability.
- **Likelihood**: Unnormalized (intractable partition function).
- **Sampling**: Very slow — requires MCMC or Langevin dynamics.
- **Use Cases**: Uncertainty modeling, compositional generation.
- **Example Models**: Score-based EBMs
- [Go to EBMs →](ebm.qmd)

</details>

<details>
<summary><strong> Diffusion Models</strong></summary>

- **Core Idea**: Learn to reverse a gradual noise process via denoising.
- **Likelihood**: Approximate (via variational bound).
- **Sampling**: Slow — requires hundreds of reverse steps.
- **Use Cases**: High-resolution image and audio generation.
- **Example Models**: Stable Diffusion
- [Go to Diffusion Models →]

</details>


## Industry Use Cases

<details>
<summary><strong>Banking</strong></summary>

- **Customer Service** — Autoregressive Models (e.g., GPT)  
- **Fraud Detection** — Energy-Based Models  
- **Operational Efficiency** — RAG for document automation and summarization  
- **Business Intelligence** — VAE for anomaly detection in transaction patterns 
- **Marketing** — GANs for personalized message generation and segmentation  

Includes deployments by JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley.  
[View full Banking use cases →](gen-ai-use-cases/banking-use-cases.html)

</details>

<details>
<summary><strong>Healthcare</strong></summary>

- **Clinical Documentation** — Autoregressive Models (e.g., GPT-4), RAG (Nuance DAX)  
- **Medical Imaging** — Diffusion Models for image enhancement  
- **Diagnostics & Triage** — VAEs for uncertainty-aware diagnosis  
- **Patient Education** — Conversational AI built on large language models  
- **Drug Discovery** — Normalizing Flows for molecular sampling and VAEs for molecule generation  

Highlights work by Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine.  
[View full Healthcare use cases →](gen-ai-use-cases/healthcare-use-cases.html)

</details>
