---
title: "Deep Generative Models"
---

## Evolution of AI Capabilities

AI is changing fast, and each stage brings new strengths, limits, and oversight needs. The table below offers a comparison of how Traditional AI, Generative AI, and Agentic AI differ in behavior and best use.


<div style="overflow-x:auto;">

| Capability            | **Traditional AI**<br><small>Rule-driven tools</small> | **Generative AI**<br><small>Smart assistants</small> | **Agentic AI**<br><small>Autonomous actors</small> |
|-----------------------|---------------------------------------------|--------------------------------------------|--------------------------------------------|
| **What it does**      | Follows hard-coded logic and rules          | Understands prompts and generates output   | Plans, reasons, and acts across steps       |
| **How it behaves**    | Rigid, predictable                          | Creative but guided                        | Goal-seeking and adaptive                   |
| **Human involvement** | Fully manual setup and supervision          | Needs context and oversight                | Can operate independently (with guardrails) |
| **Strengths**         | Reliable on structured tasks                | Great at summarizing, drafting, generating | Handles multistep workflows                 |
| **Best used for**     | Repetitive decisions and automation         | Insight generation and copiloting          | Full process orchestration                  |

</div>


## Why Generative AI Matters

Generative AI models can create entirely new content — such as text, images, simulations, or code — by learning from existing data. Unlike traditional AI systems that classify or tag inputs, generative models **produce** new outputs based on patterns they’ve learned.

Since 2022, innovation in this space has accelerated rapidly. Foundation models like ChatGPT, Claude, and Gemini are being deployed across industries — from writing assistance and image generation to fraud detection and synthetic data creation.

> **Business impact:** McKinsey estimates that generative AI could contribute up to **$4.4 trillion in annual global economic value**, with wide-ranging implications for productivity, personalization, and decision support.

At the same time, generative AI introduces new risks. Outputs may appear convincing but be inaccurate, biased, or open to misuse. This is especially critical in high-stakes domains such as banking, healthcare, and law.  
Ensuring responsible use requires strong governance, human oversight, and ethical deployment practices.


## How Generative Models Work

Generative AI models aim to learn the underlying distribution of real-world data, typically denoted as $p_{\text{data}}(x)$. Their goal is to approximate this distribution as closely as possible.

![**Figure:** Learning to Approximate the Data Distribution. Adapted from Stanford CS236 course material.](images/gen-ai.png)

> Generative models aim to approximate the real-world data distribution $P_{\text{data}}$ by learning a model distribution $P_\theta$, chosen from a parameterized family. During training, the model adjusts parameters $\theta$ to minimize the divergence $d(P_{\text{data}}, P_\theta)$, which is often equivalent to maximizing the expected log-likelihood of observed data under $P_\theta$. Once trained, new samples are generated by drawing from this learned distribution.

- The distribution learned by the model is denoted as $p_\theta(x)$  
- We generate new data by **sampling** from this learned distribution  
- In practice, generative models are trained to **maximize the expected log-likelihood** of $p_\theta(x)$, or equivalently, **minimize the divergence** between $p_\theta(x)$ and $p_{\text{data}}(x)$


> **Note**:  
> - Models like **Autoregressive models** and **Normalizing Flows** directly maximize log-likelihood.  
> - **VAEs** maximize a variational lower bound (ELBO) on log-likelihood.  
> - **GANs** minimize the **Jensen-Shannon divergence** through adversarial training.  
> - **Diffusion models** and **EBMs** use score matching or other divergence-minimizing techniques.


## Key Gen AI Model Families

These foundational architectures form the backbone of modern GenAI applications. Each family differs in how it models data distributions, handles sampling and inference, and supports various real-world use cases.

### Variational Autoencoders (VAEs)
- **Core Idea**: Encode input into a latent space and reconstruct while optimizing a lower bound on likelihood (ELBO).
- **Likelihood**: Approximate (variational lower bound).
- **Sampling**: Fast — sample latent vector and decode.
- **Use Cases**: Representation learning, image generation.
- **Example Models**: β-VAE, Conditional VAE  
- [Go to VAE Models →](vae.qmd)

### Autoregressive Models
- **Core Idea**: Factor the joint distribution as a product of conditional probabilities.
- **Likelihood**: Exact.
- **Sampling**: Slow — token-by-token generation.
- **Use Cases**: Language modeling, code generation, time series.
- **Example Models**: GPT, PixelRNN  
- [Go to Autoregressive Models →]

### Normalizing Flows
- **Core Idea**: Learn invertible transformations using the change-of-variable formula.
- **Likelihood**: Exact and tractable.
- **Sampling**: Fast — sample from base distribution and invert.
- **Use Cases**: Density estimation, latent space modeling.
- **Example Models**: RealNVP, Glow  
- [Go to Flow Models →](flows.qmd)

### Energy-Based Models (EBMs)
- **Core Idea**: Define an energy function over inputs; lower energy = higher probability.
- **Likelihood**: Unnormalized (intractable partition function).
- **Sampling**: Very slow — requires MCMC or Langevin dynamics.
- **Use Cases**: Uncertainty modeling, compositional generation.
- **Example Models**: Score-based EBMs  
- [Go to EBMs →](ebm.qmd)

### Generative Adversarial Networks (GANs)
- **Core Idea**: Generator and discriminator compete in a minimax game to produce realistic samples.
- **Likelihood**: None (implicit model).
- **Sampling**: Fast — sample latent vector and pass through generator.
- **Use Cases**: High-quality image generation, style transfer.
- **Example Models**: StyleGAN, CycleGAN  
- [Go to GAN Models →]

### Diffusion Models
- **Core Idea**: Learn to reverse a gradual noise process via denoising.
- **Likelihood**: Approximate (via variational bound).
- **Sampling**: Slow — requires hundreds of reverse steps.
- **Use Cases**: High-resolution image and audio generation.
- **Example Models**: Stable Diffusion  
- [Go to Diffusion Models →](diffusion.qmd)


::: {.callout-tip title="Explore Related Topics"}
Expand your understanding of Generative AI with these supporting deep dives:

- [Transformers →](transformers.qmd)  
  Understand the self-attention architecture behind modern LLMs and Gen AI models.

- [Post-Training Techniques →](post-training.qmd)  
  Learn how fine-tuning, RLHF, and instruction tuning make base models usable in the real world.

- [Evaluation Strategies →](nlp-eval.qmd)  
  Discover how we evaluate GenAI output quality — from traditional metrics to modern LLM-based approaches.
:::

## Use-Case Framing & Prioritization

Before diving into specific industry use cases, it's critical to assess *where* and *how* generative AI can deliver real value. Not every idea is equally feasible, impactful, or low-risk. A structured framing process helps ensure that AI initiatives align with business priorities and responsible innovation.

We recommend evaluating GenAI use cases across three key dimensions:

- **Business Value**: Consider how the use case impacts revenue generation, cost reduction, operational efficiency, risk mitigation, or customer experience. This ensures alignment with strategic business outcomes.

- **Feasibility**: Evaluate the availability and quality of data, the readiness of models, the complexity of integration, and infrastructure or compute requirements. This grounds ideas in technical and operational reality.

- **Governance Sensitivity**: Assess how much oversight is needed to meet regulatory, ethical, or reputational expectations—especially in domains like banking and healthcare. This includes explainability, auditability, and the potential for misuse.

This framing helps prioritize AI use cases that are not only **promising**, but also **implementable** and **sustainable**—especially in highly regulated environments.

---

## Industry Use Cases

### Banking

| **Use Case**             | **Model Type**                   | **Example Application**                                               |
|--------------------------|----------------------------------|------------------------------------------------------------------------|
| **Customer Service**     | Autoregressive (e.g., GPT)       | Virtual agents for handling account queries and FAQs                  |
| **Fraud Detection**      | Energy-Based Models              | Real-time anomaly detection in transaction behavior                   |
| **Operational Efficiency** | RAG (Retrieval-Augmented Gen)  | Automating call summaries and back-office document workflows          |
| **Business Intelligence** | VAEs (Variational Autoencoders) | Detecting anomalies in product or branch-level KPIs                   |
| **Marketing & Personalization** | GANs                    | Generating personalized offers based on behavioral segmentation       |

> Includes deployments by JPMorgan, Mastercard, Wells Fargo, and Morgan Stanley. [View more details on Banking use cases →](gen-ai-use-cases/banking-use-cases.html)

---

### Healthcare

| **Use Case**             | **Model Type**                            | **Example Application**                                                   |
|--------------------------|-------------------------------------------|----------------------------------------------------------------------------|
| **Clinical Documentation** | GPT-4, RAG (Nuance DAX)                 | Auto-generating visit summaries and physician notes                        |
| **Medical Imaging**      | Diffusion Models                          | Enhancing and reconstructing radiological images                          |
| **Diagnostics & Triage** | VAEs                                      | Supporting diagnosis with uncertainty-aware modeling                      |
| **Patient Education**    | Conversational AI                         | Explaining test results in accessible, human-like language                |
| **Drug Discovery**       | Normalizing Flows, VAEs                   | Accelerating compound generation and molecular simulation                 |

> Highlights include work by Nuance (Microsoft), Mayo Clinic, DeepMind, and Insilico Medicine. [View more details on Healthcare use cases →](gen-ai-use-cases/healthcare-use-cases.html)


## Governance & Risk Warnings

Generative AI introduces exciting new capabilities—but also carries **unique risks** that traditional analytics and rules-based systems did not. Without strong governance, these risks can quickly undermine trust, compliance, and effectiveness.

**Key Risks to Watch:**

- **Inaccuracy & Hallucination**: GenAI can confidently generate responses that sound right—but are completely wrong or misleading.
- **Bias & Fairness**: Models can unintentionally reinforce historical bias found in training data. These outcomes could affect customers or patients.
- **Security & Privacy**: Prompts or training data may inadvertently expose sensitive, private, or proprietary information.
- **Overtrust**: Users may take outputs at face value without critical thinking, especially in high-volume environments like BI dashboards or chatbots.
- **Regulatory Exposure**: Lack of transparency, explainability, or auditability may put the organization at odds with standards such as OCC guidelines, HIPAA, GDPR, or emerging AI laws.

**Governance Practices to Put in Place:**

- **Human-in-the-Loop (HITL)**: Require review and validation for GenAI-generated content in regulated or customer-facing contexts.
- **Explainability & Traceability**: Where possible, use interpretable model frameworks, or add metadata like model version, confidence score, or decision path.
- **Prompt & Output Logging**: Maintain logs of GenAI usage for auditing, debugging, and continuous refinement.
- **Access Control & Masking**: Limit who can access GenAI systems and ensure sensitive data is redacted before prompt injection or model training.
- **Alignment with Ethical and Regulatory Frameworks**: Embed enterprise values and industry-specific compliance into your AI lifecycle—from design to deployment.

> **Bottom line**: In highly regulated industries like banking and healthcare, governance isn't just a best practice—it's a business requirement. The goal is to innovate *responsibly* and scale *safely*.

## Conclusion

Generative AI is more than a technological breakthrough — it represents a fundamental shift in how content is created and consumed. As organizations move beyond isolated experiments, the focus will shift toward embedding GenAI into real workflows, governed environments, and long-term value creation.

Looking ahead, the next wave of GenAI will be defined by intelligent copilots, adaptive agents, and deeply integrated AI layers that understand industry context and human intent. This evolution will demand strong foundations in model governance, strategic use case alignment, and scalable architecture — exactly the pillars explored in this guide.