{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c4c9d3b",
      "metadata": {
        "id": "0c4c9d3b"
      },
      "source": [
        "# Energy-Based Model (EBM) on MNIST\n",
        "This notebook implements a basic EBM using PyTorch and MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b360119",
      "metadata": {
        "id": "8b360119"
      },
      "outputs": [],
      "source": [
        "# Install and import dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "BhGGNV-iz5zF"
      },
      "id": "BhGGNV-iz5zF",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.0001\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "qrcm8WgashQX"
      },
      "id": "qrcm8WgashQX",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------\n",
        "# Load the MNIST dataset in PyTorch\n",
        "# ------------------------------------------\n",
        "\n",
        "# Step 1: Define a transform to convert images to PyTorch tensors\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts images to range [0, 1] as float32 tensors\n",
        "])\n",
        "\n",
        "# Step 2: Download and load the training and test sets\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Step 3: Create DataLoaders for easy batch access\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "-jia9pjnrMZY"
      },
      "id": "-jia9pjnrMZY",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------\n",
        "# Custom preprocessing function (if needed)\n",
        "# ------------------------------------------\n",
        "\n",
        "def preprocess_pytorch(images):\n",
        "    \"\"\"\n",
        "    Normalize and reshape the images similar to your original TensorFlow preprocessing.\n",
        "\n",
        "    - Normalize pixel values from [0, 255] → [-1, 1]\n",
        "    - Pad from 28x28 → 32x32 with constant value -1\n",
        "    - Add a channel dimension if not present\n",
        "    \"\"\"\n",
        "\n",
        "    # Scale from [0, 1] to [-1, 1]\n",
        "    images = images * 2 - 1\n",
        "\n",
        "    # images: shape (batch_size, 1, 28, 28) → pad to (batch_size, 1, 32, 32)\n",
        "    images = F.pad(images, pad=(2, 2, 2, 2), mode='constant', value=-1.0)\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "mrCPUOpErh2D"
      },
      "id": "mrCPUOpErh2D",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),         # Converts image to [0, 1] tensor\n",
        "    transforms.Lambda(preprocess_pytorch)  # Then normalize and pad\n",
        "])"
      ],
      "metadata": {
        "id": "XZIQRiDJrw3b"
      },
      "id": "XZIQRiDJrw3b",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MNIST dataset\n",
        "mnist_data = datasets.MNIST(root='.', train=True, download=True)\n",
        "x_train = mnist_data.data.numpy()\n",
        "\n",
        "mnist_test = datasets.MNIST(root='.', train=False, download=True)\n",
        "x_test = mnist_test.data.numpy()"
      ],
      "metadata": {
        "id": "L3zYxgUDtXLi"
      },
      "id": "L3zYxgUDtXLi",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numpy arrays to PyTorch tensors and add channel dimension\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).unsqueeze(1)  # shape: [B, 1, 28, 28]\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).unsqueeze(1)    # shape: [B, 1, 28, 28]\n",
        "\n",
        "# Create TensorDatasets from tensors\n",
        "train_dataset = TensorDataset(x_train_tensor)\n",
        "test_dataset = TensorDataset(x_test_tensor)\n",
        "\n",
        "# Wrap datasets in DataLoader to enable batching and shuffling\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "ejY9Evz7sO6I"
      },
      "id": "ejY9Evz7sO6I",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PyTorch EBM model similar to your TensorFlow implementation\n",
        "class EBM(nn.Module):\n",
        "    def __init__(self, image_size=28, channels=1):\n",
        "        super(EBM, self).__init__()\n",
        "\n",
        "        # Convolutional layers with Swish (SiLU) activations\n",
        "        self.conv1 = nn.Conv2d(channels, 16, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Calculate the flattened output size after 4 conv layers\n",
        "        conv_output_size = image_size // (2**4)  # 4 strides of 2\n",
        "        flattened_dim = 64 * conv_output_size * conv_output_size\n",
        "\n",
        "        # Dense layers\n",
        "        self.fc1 = nn.Linear(flattened_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)  # Single energy output\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Swish activation is available as F.silu in PyTorch\n",
        "        x = F.silu(self.conv1(x))\n",
        "        x = F.silu(self.conv2(x))\n",
        "        x = F.silu(self.conv3(x))\n",
        "        x = F.silu(self.conv4(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten for dense layers\n",
        "        x = F.silu(self.fc1(x))\n",
        "        energy = self.fc2(x)  # Output energy (unnormalized score)\n",
        "        return energy"
      ],
      "metadata": {
        "id": "aMbcNTuBwCxK"
      },
      "id": "aMbcNTuBwCxK",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(\n",
        "    model,                 # The energy-based model\n",
        "    inp_imgs,              # Initial images (random noise or seeds)\n",
        "    steps,                 # Number of Langevin steps\n",
        "    step_size,             # Step size (learning rate)\n",
        "    noise,                 # Stddev of added Gaussian noise\n",
        "    return_img_per_step=False,  # Whether to save images at each step\n",
        "):\n",
        "    imgs_per_step = []\n",
        "\n",
        "    inp_imgs = inp_imgs.clone().detach().to(device).requires_grad_(True)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Step 1: Add Gaussian noise to encourage exploration\n",
        "        inp_imgs.data += torch.randn_like(inp_imgs) * noise\n",
        "\n",
        "        # Step 2: Clamp values to stay in [-1, 1] range (MNIST normalized)\n",
        "        inp_imgs.data = torch.clamp(inp_imgs.data, -1.0, 1.0)\n",
        "\n",
        "        # Step 3: Forward pass to compute score (energy)\n",
        "        out_score = model(inp_imgs)\n",
        "\n",
        "        # Step 4: Compute gradient of score w.r.t. input image\n",
        "        grads = torch.autograd.grad(outputs=out_score.sum(), inputs=inp_imgs)[0]\n",
        "\n",
        "        # Step 5: Clip gradients for stability\n",
        "        grads = torch.clamp(grads, -GRADIENT_CLIP, GRADIENT_CLIP)\n",
        "\n",
        "        # Step 6: Gradient ascent step on input image\n",
        "        inp_imgs.data += step_size * grads\n",
        "\n",
        "        # Step 7: Clamp again to stay in valid range\n",
        "        inp_imgs.data = torch.clamp(inp_imgs.data, -1.0, 1.0)\n",
        "\n",
        "        if return_img_per_step:\n",
        "            imgs_per_step.append(inp_imgs.detach().clone())\n",
        "\n",
        "    if return_img_per_step:\n",
        "        return torch.stack(imgs_per_step, dim=0)\n",
        "    else:\n",
        "        return inp_imgs.detach()"
      ],
      "metadata": {
        "id": "Rg7ysQkawqiK"
      },
      "id": "Rg7ysQkawqiK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EBM(nn.Module):\n",
        "    def __init__(self, base_model, alpha=0.1):\n",
        "        super().__init__()\n",
        "        self.model = base_model  # scoring network\n",
        "        self.alpha = alpha       # regularization weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n",
        "\n",
        "def compute_loss(model, real_imgs, steps, step_size, noise_scale):\n",
        "    \"\"\"\n",
        "    Contrastive divergence loss between real data and fake (noise) samples.\n",
        "    \"\"\"\n",
        "    batch_size = real_imgs.size(0)\n",
        "\n",
        "    # Generate fake images from random noise\n",
        "    fake_imgs = torch.empty_like(real_imgs).uniform_(-1, 1).to(real_imgs.device)\n",
        "    fake_imgs.requires_grad = True\n",
        "\n",
        "    # Langevin dynamics steps (optional: here 0 steps means no update)\n",
        "    for _ in range(steps):\n",
        "        fake_imgs.data += torch.randn_like(fake_imgs) * noise_scale\n",
        "        fake_imgs.data = torch.clamp(fake_imgs.data, -1, 1)\n",
        "\n",
        "        energy = model(fake_imgs)\n",
        "        grads = torch.autograd.grad(energy.sum(), fake_imgs, create_graph=True)[0]\n",
        "        fake_imgs.data += step_size * grads\n",
        "        fake_imgs.data = torch.clamp(fake_imgs.data, -1, 1)\n",
        "\n",
        "    # Get scores\n",
        "    real_scores = model(real_imgs)\n",
        "    fake_scores = model(fake_imgs.detach())\n",
        "\n",
        "    # Contrastive Divergence (CD-1) Loss\n",
        "    cdiv_loss = fake_scores.mean() - real_scores.mean()\n",
        "\n",
        "    # Regularization: penalize high scores\n",
        "    reg_loss = model.alpha * ((real_scores ** 2).mean() + (fake_scores ** 2).mean())\n",
        "\n",
        "    total_loss = cdiv_loss + reg_loss\n",
        "\n",
        "    return total_loss, cdiv_loss.item(), reg_loss.item(), real_scores.mean().item(), fake_scores.mean().item()"
      ],
      "metadata": {
        "id": "hGa-pB8dxG2W"
      },
      "id": "hGa-pB8dxG2W",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScoreNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # [batch, 32, 14, 14]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # [batch, 64, 7, 7]\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)  # Final scalar output (energy score)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "qnKgQnG-xkQT"
      },
      "id": "qnKgQnG-xkQT",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ScoreNet()\n",
        "ebm = EBM(base_model=base_model, alpha=0.1)"
      ],
      "metadata": {
        "id": "jYFqkQR9xnPl"
      },
      "id": "jYFqkQR9xnPl",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ebm = ebm.to(device)  # Move the model to the device"
      ],
      "metadata": {
        "id": "NzM1C5SQ4R-8"
      },
      "id": "NzM1C5SQ4R-8",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(ebm.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "Vjhp5eKExyts"
      },
      "id": "Vjhp5eKExyts",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for batch in train_loader:\n",
        "        if isinstance(batch, (list, tuple)):\n",
        "            real_images = batch[0]\n",
        "        else:\n",
        "            real_images = batch\n",
        "\n",
        "        real_images = real_images.to(device)\n",
        "        real_images.requires_grad = True\n",
        "\n",
        "        # Forward pass\n",
        "        scores = ebm(real_images)\n",
        "        loss = -scores.mean()  # Basic negative log-score loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "QWhOxfaSx18k",
        "outputId": "dd2cf25e-57e7-4f82-bafb-f24844b24e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QWhOxfaSx18k",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: -1949711.2500\n",
            "Epoch 2/10, Loss: -34621388.0000\n",
            "Epoch 3/10, Loss: -168554992.0000\n",
            "Epoch 4/10, Loss: -460923584.0000\n",
            "Epoch 5/10, Loss: -974023040.0000\n",
            "Epoch 6/10, Loss: -1813268352.0000\n",
            "Epoch 7/10, Loss: -2972573696.0000\n",
            "Epoch 8/10, Loss: -4526898176.0000\n",
            "Epoch 9/10, Loss: -6693363200.0000\n",
            "Epoch 10/10, Loss: -9541715968.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uZvFgDE6ZOJ"
      },
      "id": "6uZvFgDE6ZOJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}